{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMQCrwctS+KyCfCIYRLX13X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XUjMNwGDGFl",
        "outputId": "e1491c12-b331-45cb-d7e8-74ea8fa06f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cloning into 'deep-learning-retinal-classification'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (21/21), 11.18 KiB | 11.18 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "/content/deep-learning-retinal-classification\n",
            "‚úÖ Repositorio conectado!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive (opcional pero recomendado)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clonar tu repositorio\n",
        "GITHUB_USER = \"PieroCampos\"\n",
        "REPO_NAME = \"deep-learning-retinal-classification\"\n",
        "\n",
        "# Si es primera vez\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/PieroCampos/deep-learning-retinal-classification.git\n",
        "    %cd {REPO_NAME}\n",
        "else:\n",
        "    %cd {REPO_NAME}\n",
        "    !git pull\n",
        "\n",
        "print(\"‚úÖ Repositorio conectado!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalar dependencias\n",
        "\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q timm  # Para modelos pre-entrenados\n",
        "!pip install -q scikit-learn pandas matplotlib seaborn\n",
        "!pip install -q kaggle  # Para descargar dataset"
      ],
      "metadata": {
        "id": "1DRSNt67G2-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 3: Montar Google Drive\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"üìÅ Montando Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n‚úÖ Google Drive montado!\")\n",
        "print(\"\\nüìÇ Verificando archivos en Drive...\")\n",
        "\n",
        "# Listar contenido de tu carpeta del proyecto\n",
        "!ls -lh \"/content/drive/MyDrive/DL_Project_ODIR/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-20RC-jSwRT",
        "outputId": "39f9d395-1aa3-4037-eda0-15f1738f64f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Montando Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "‚úÖ Google Drive montado!\n",
            "\n",
            "üìÇ Verificando archivos en Drive...\n",
            "total 64M\n",
            "-rw------- 1 root root 64M Dec 28 23:27 final-project-deep-learning-fall-2025.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 4: Extraer dataset desde Google Drive\n",
        "# ============================================\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Crear directorio para datos\n",
        "!mkdir -p ./data\n",
        "\n",
        "# Ruta al archivo ZIP en tu Drive\n",
        "zip_path = \"/content/drive/MyDrive/DL_Project_ODIR/final-project-deep-learning-fall-2025.zip\"\n",
        "\n",
        "# Verificar que existe\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"‚úÖ Archivo encontrado: {zip_path}\")\n",
        "    print(f\"üì¶ Tama√±o: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n",
        "    print(\"\\nüîÑ Descomprimiendo... (esto puede tomar 2-3 minutos)\")\n",
        "\n",
        "    # Descomprimir\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('./data')\n",
        "\n",
        "    print(\"\\n‚úÖ ¬°Dataset extra√≠do correctamente!\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ùå No se encontr√≥ el archivo en: {zip_path}\")\n",
        "    print(\"\\nüîç Archivos disponibles en tu carpeta:\")\n",
        "    !ls \"/content/drive/MyDrive/DL_Project_ODIR/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6kTdO9FT_sj",
        "outputId": "ec6f7910-b2bf-47c7-808f-04b53be83f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Archivo encontrado: /content/drive/MyDrive/DL_Project_ODIR/final-project-deep-learning-fall-2025.zip\n",
            "üì¶ Tama√±o: 63.10 MB\n",
            "\n",
            "üîÑ Descomprimiendo... (esto puede tomar 2-3 minutos)\n",
            "\n",
            "‚úÖ ¬°Dataset extra√≠do correctamente!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Verificar estructura del dataset\n",
        "# ============================================\n",
        "import os\n",
        "\n",
        "print(\"üìä ESTRUCTURA DEL DATASET:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Funci√≥n para mostrar √°rbol de directorios\n",
        "def show_tree(path, prefix=\"\", max_files=10):\n",
        "    try:\n",
        "        items = sorted(os.listdir(path))\n",
        "        dirs = [i for i in items if os.path.isdir(os.path.join(path, i))]\n",
        "        files = [i for i in items if os.path.isfile(os.path.join(path, i))]\n",
        "\n",
        "        # Mostrar directorios\n",
        "        for d in dirs:\n",
        "            print(f\"{prefix}üìÅ {d}/\")\n",
        "            show_tree(os.path.join(path, d), prefix + \"  \", max_files)\n",
        "\n",
        "        # Mostrar archivos\n",
        "        for i, f in enumerate(files):\n",
        "            if i < max_files:\n",
        "                size = os.path.getsize(os.path.join(path, f))\n",
        "                size_str = f\"{size/1024:.1f} KB\" if size < 1024*1024 else f\"{size/(1024*1024):.1f} MB\"\n",
        "                print(f\"{prefix}üìÑ {f} ({size_str})\")\n",
        "            elif i == max_files:\n",
        "                print(f\"{prefix}   ... y {len(files) - max_files} archivos m√°s\")\n",
        "                break\n",
        "\n",
        "    except PermissionError:\n",
        "        print(f\"{prefix} Sin permisos\")\n",
        "\n",
        "show_tree('./data')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Contar im√°genes si existen\n",
        "if os.path.exists('./data/images'):\n",
        "    num_images = len([f for f in os.listdir('./data/images') if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    print(f\"üì∏ Total de im√°genes encontradas: {num_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcIzmDFAUS01",
        "outputId": "697550ba-7af2-4d8a-9bab-7f85cb916815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä ESTRUCTURA DEL DATASET:\n",
            "============================================================\n",
            "üìÅ final_project_resources/\n",
            "  üìÅ .idea/\n",
            "    üìÅ inspectionProfiles/\n",
            "      üìÑ profiles_settings.xml (0.2 KB)\n",
            "    üìÑ .gitignore (0.0 KB)\n",
            "    üìÑ final_project_resources.iml (0.3 KB)\n",
            "    üìÑ misc.xml (0.3 KB)\n",
            "    üìÑ modules.xml (0.3 KB)\n",
            "    üìÑ workspace.xml (2.0 KB)\n",
            "  üìÅ images/\n",
            "    üìÅ offsite_test/\n",
            "      üìÑ 102_left.jpg (7.3 KB)\n",
            "      üìÑ 1071_left.jpg (7.4 KB)\n",
            "      üìÑ 1147_right.jpg (8.5 KB)\n",
            "      üìÑ 1210_left.jpg (5.1 KB)\n",
            "      üìÑ 1212_left.jpg (6.4 KB)\n",
            "      üìÑ 1221_right.jpg (4.5 KB)\n",
            "      üìÑ 1229_left.jpg (5.2 KB)\n",
            "      üìÑ 1234_left.jpg (6.6 KB)\n",
            "      üìÑ 1237_right.jpg (6.3 KB)\n",
            "      üìÑ 1239_left.jpg (6.2 KB)\n",
            "         ... y 190 archivos m√°s\n",
            "    üìÅ onsite_test/\n",
            "      üìÑ 1022_left.jpg (5.6 KB)\n",
            "      üìÑ 1022_right.jpg (5.3 KB)\n",
            "      üìÑ 102_right.jpg (7.8 KB)\n",
            "      üìÑ 1071_right.jpg (7.5 KB)\n",
            "      üìÑ 1082_right.jpg (6.8 KB)\n",
            "      üìÑ 1138_right.jpg (5.8 KB)\n",
            "      üìÑ 1157_right.jpg (7.3 KB)\n",
            "      üìÑ 1167_right.jpg (5.0 KB)\n",
            "      üìÑ 1196_right.jpg (6.7 KB)\n",
            "      üìÑ 11_left.jpg (7.2 KB)\n",
            "         ... y 240 archivos m√°s\n",
            "    üìÅ train/\n",
            "      üìÑ 1020_left.jpg (6.9 KB)\n",
            "      üìÑ 1035_right.jpg (8.9 KB)\n",
            "      üìÑ 1043_right.jpg (6.1 KB)\n",
            "      üìÑ 1064_left.jpg (6.8 KB)\n",
            "      üìÑ 1065_left.jpg (8.1 KB)\n",
            "      üìÑ 1075_left.jpg (6.5 KB)\n",
            "      üìÑ 1083_left.jpg (4.9 KB)\n",
            "      üìÑ 1084_left.jpg (6.7 KB)\n",
            "      üìÑ 1084_right.jpg (5.5 KB)\n",
            "      üìÑ 1085_right.jpg (7.6 KB)\n",
            "         ... y 790 archivos m√°s\n",
            "    üìÅ val/\n",
            "      üìÑ 1043_left.jpg (5.8 KB)\n",
            "      üìÑ 1064_right.jpg (6.9 KB)\n",
            "      üìÑ 1068_left.jpg (7.7 KB)\n",
            "      üìÑ 107_right.jpg (6.7 KB)\n",
            "      üìÑ 1083_right.jpg (5.4 KB)\n",
            "      üìÑ 1085_left.jpg (7.6 KB)\n",
            "      üìÑ 1091_left.jpg (6.9 KB)\n",
            "      üìÑ 1098_left.jpg (6.2 KB)\n",
            "      üìÑ 1125_right.jpg (7.1 KB)\n",
            "      üìÑ 1147_left.jpg (8.6 KB)\n",
            "         ... y 190 archivos m√°s\n",
            "  üìÅ pretrained_backbone/\n",
            "    üìÑ ckpt_efficientnet_ep50.pt (15.6 MB)\n",
            "    üìÑ ckpt_resnet18_ep50.pt (42.7 MB)\n",
            "  üìÑ code_template.py (6.7 KB)\n",
            "  üìÑ offsite_test.csv (4.0 KB)\n",
            "  üìÑ onsite_test_submission.csv (5.2 KB)\n",
            "  üìÑ train.csv (15.8 KB)\n",
            "  üìÑ val.csv (3.9 KB)\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 6: Verificar archivos CSV\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "\n",
        "print(\"üìã VERIFICANDO ARCHIVOS CSV:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Lista de archivos esperados\n",
        "csv_files = {\n",
        "    'train.csv': './data/final_project_resources/train.csv',\n",
        "    'val.csv': './data/final_project_resources/val.csv',\n",
        "    'offsite_test.csv': './data/final_project_resources/offsite_test.csv',\n",
        "    'onsite_test_submission.csv': './data/final_project_resources/onsite_test_submission.csv'\n",
        "}\n",
        "\n",
        "for name, path in csv_files.items():\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"\\n‚úÖ {name}\")\n",
        "        print(f\"   Filas: {len(df)}\")\n",
        "        print(f\"   Columnas: {list(df.columns)}\")\n",
        "        print(f\"   Primeras filas:\")\n",
        "        print(df.head(2).to_string(index=False))\n",
        "    else:\n",
        "        print(f\"\\n‚ùå {name} - NO ENCONTRADO\")\n",
        "        print(f\"   Buscando en: {path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sCMhcBGUost",
        "outputId": "1b01ac9b-f2cf-478a-8522-49908a3b3717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã VERIFICANDO ARCHIVOS CSV:\n",
            "============================================================\n",
            "\n",
            "‚úÖ train.csv\n",
            "   Filas: 800\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "           id  D  G  A\n",
            "913_right.jpg  1  0  0\n",
            " 281_left.jpg  1  0  0\n",
            "\n",
            "‚úÖ val.csv\n",
            "   Filas: 200\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "           id  D  G  A\n",
            "184_right.jpg  1  0  0\n",
            "4488_left.jpg  1  0  0\n",
            "\n",
            "‚úÖ offsite_test.csv\n",
            "   Filas: 200\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "           id  D  G  A\n",
            "568_right.jpg  1  0  0\n",
            " 748_left.jpg  1  0  0\n",
            "\n",
            "‚úÖ onsite_test_submission.csv\n",
            "   Filas: 250\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "            id  D  G  A\n",
            "4595_right.jpg  0  0  0\n",
            " 4155_left.jpg  0  0  0\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1.1"
      ],
      "metadata": {
        "id": "UUMIP9mwysyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 1: TRANSFER LEARNING\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" INICIANDO TASK 1: TRANSFER LEARNING\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr2cQYUJjG8i",
        "outputId": "7f244d98-a069-47e8-9bb5-293002107b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " INICIANDO TASK 1: TRANSFER LEARNING\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Importar librer√≠as necesarias para Task 1\n",
        "# ============================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "print(\" Librer√≠as importadas!\")\n",
        "print(f\" Device disponible: {'GPU ' if torch.cuda.is_available() else 'CPU '}\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1G0tXPyjP0e",
        "outputId": "c5b356da-4a6a-42bd-806b-dd931b757d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Librer√≠as importadas!\n",
            " Device disponible: GPU \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Clase Dataset (Multi-label)\n",
        "# ============================================\n",
        "class RetinaMultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "print(\" Clase Dataset definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQTniocljfG2",
        "outputId": "e602a0b6-0207-4c66-c748-099327285c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Clase Dataset definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n para construir modelos\n",
        "# ============================================\n",
        "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=False):\n",
        "    \"\"\"\n",
        "    Construye un modelo con el backbone especificado.\n",
        "\n",
        "    Args:\n",
        "        backbone: 'resnet18' o 'efficientnet'\n",
        "        num_classes: n√∫mero de clases (3 para DR, G, AMD)\n",
        "        pretrained: usar pesos de ImageNet (no usado aqu√≠)\n",
        "    \"\"\"\n",
        "    if backbone == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif backbone == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(pretrained=pretrained)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Backbone no soportado: {backbone}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\" Funci√≥n build_model definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8OKvF5jm5t",
        "outputId": "d04a679e-daf6-4e2a-8182-13c97ea4142c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n build_model definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n de evaluaci√≥n\n",
        "# ============================================\n",
        "def evaluate_model(model, test_loader, device, dataset_name=\"Test\"):\n",
        "    \"\"\"\n",
        "    Eval√∫a un modelo y retorna m√©tricas por enfermedad.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    disease_names = [\"DR\", \"G\", \"AMD\"]\n",
        "    results = {}\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" RESULTADOS - {dataset_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    f_scores = []\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        precision = precision_score(y_t, y_p, zero_division=0)\n",
        "        recall = recall_score(y_t, y_p, zero_division=0)\n",
        "        f1 = f1_score(y_t, y_p, zero_division=0)\n",
        "\n",
        "        results[disease] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "\n",
        "        f_scores.append(f1)\n",
        "\n",
        "        print(f\"\\n{disease}:\")\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "        print(f\"  Recall:    {recall:.4f}\")\n",
        "        print(f\"  F-score:   {f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f_scores)\n",
        "    results['average_f1'] = avg_f1\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" AVERAGE F-SCORE: {avg_f1:.4f}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\" Funci√≥n evaluate_model definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aEYihJNjttK",
        "outputId": "c3395931-cac4-4f7b-edf4-f5ae4a933ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n evaluate_model definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.1 - No Fine-tuning\n",
        "# Evaluar modelos pre-entrenados sin modificaci√≥n\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" TASK 1.1: NO FINE-TUNING\")\n",
        "print(\"   Evaluando modelos pre-entrenados directamente en ODIR test set\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Configuraci√≥n de rutas\n",
        "BASE_DIR = \"./data/final_project_resources\"\n",
        "offsite_test_csv = f\"{BASE_DIR}/offsite_test.csv\"\n",
        "offsite_test_dir = f\"{BASE_DIR}/images/offsite_test\"\n",
        "\n",
        "# Transform (mismo que se us√≥ en pre-entrenamiento)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Crear dataset y dataloader para offsite test\n",
        "offsite_test_ds = RetinaMultiLabelDataset(\n",
        "    offsite_test_csv,\n",
        "    offsite_test_dir,\n",
        "    transform\n",
        ")\n",
        "\n",
        "offsite_test_loader = DataLoader(\n",
        "    offsite_test_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\" Offsite test set cargado: {len(offsite_test_ds)} im√°genes\\n\")\n",
        "\n",
        "# Almacenar resultados\n",
        "task1_1_results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXJA5n_6j5Ga",
        "outputId": "c5662110-cb6c-4659-99c8-64ee87a57ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " TASK 1.1: NO FINE-TUNING\n",
            "   Evaluando modelos pre-entrenados directamente en ODIR test set\n",
            "================================================================================\n",
            "\n",
            " Offsite test set cargado: 200 im√°genes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18\n",
        "# ========================\n",
        "print(\" EVALUANDO RESNET18\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "resnet_model = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_pretrained_path = f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\"\n",
        "\n",
        "# Cargar pesos pre-entrenados\n",
        "state_dict = torch.load(resnet_pretrained_path, map_location=DEVICE)\n",
        "resnet_model.load_state_dict(state_dict)\n",
        "\n",
        "print(f\" Pesos cargados desde: {resnet_pretrained_path}\\n\")\n",
        "\n",
        "# Evaluar\n",
        "resnet_results = evaluate_model(\n",
        "    resnet_model,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - No Fine-tuning - Offsite Test\"\n",
        ")\n",
        "\n",
        "task1_1_results['resnet18'] = resnet_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fK0sGjFkFOM",
        "outputId": "0b1152fe-b40f-4d4c-9bac-eebc6d3ee59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " EVALUANDO RESNET18\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pesos cargados desde: ./data/final_project_resources/pretrained_backbone/ckpt_resnet18_ep50.pt\n",
            "\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - No Fine-tuning - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.7172\n",
            "  Recall:    0.5071\n",
            "  F-score:   0.5941\n",
            "\n",
            "G:\n",
            "  Precision: 0.5750\n",
            "  Recall:    0.4694\n",
            "  F-score:   0.5169\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.3019\n",
            "  Recall:    0.7273\n",
            "  F-score:   0.4267\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.5126\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar EfficientNet\n",
        "# ========================\n",
        "print(\"\\n EVALUANDO EFFICIENTNET\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "effnet_model = build_model(\"efficientnet\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "effnet_pretrained_path = f\"{BASE_DIR}/pretrained_backbone/ckpt_efficientnet_ep50.pt\"\n",
        "\n",
        "# Cargar pesos pre-entrenados\n",
        "state_dict = torch.load(effnet_pretrained_path, map_location=DEVICE)\n",
        "effnet_model.load_state_dict(state_dict)\n",
        "\n",
        "print(f\" Pesos cargados desde: {effnet_pretrained_path}\\n\")\n",
        "\n",
        "# Evaluar\n",
        "effnet_results = evaluate_model(\n",
        "    effnet_model,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"EfficientNet - No Fine-tuning - Offsite Test\"\n",
        ")\n",
        "\n",
        "task1_1_results['efficientnet'] = effnet_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJoVVu_lllGI",
        "outputId": "a7f04cae-7774-46f5-86fd-51d2a56e3e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO EFFICIENTNET\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pesos cargados desde: ./data/final_project_resources/pretrained_backbone/ckpt_efficientnet_ep50.pt\n",
            "\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - EfficientNet - No Fine-tuning - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.7459\n",
            "  Recall:    0.6500\n",
            "  F-score:   0.6947\n",
            "\n",
            "G:\n",
            "  Precision: 0.5769\n",
            "  Recall:    0.6122\n",
            "  F-score:   0.5941\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.2464\n",
            "  Recall:    0.7727\n",
            "  F-score:   0.3736\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.5541\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Resumen Task 1.1\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN TASK 1.1 - NO FINE-TUNING (Offsite Test Set)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Modelo':<15} {'Avg F-score':<15} {'Status':<20}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "resnet_f1 = task1_1_results['resnet18']['average_f1']\n",
        "effnet_f1 = task1_1_results['efficientnet']['average_f1']\n",
        "\n",
        "# Comparar con referencias\n",
        "resnet_ref = 56.7\n",
        "effnet_ref = 60.4\n",
        "\n",
        "resnet_status = \" Comparable\" if resnet_f1 >= resnet_ref * 0.9 else \" Bajo\"\n",
        "effnet_status = \" Comparable\" if effnet_f1 >= effnet_ref * 0.9 else \" Bajo\"\n",
        "\n",
        "print(f\"{'ResNet18':<15} {resnet_f1*100:>6.2f}%         {resnet_status}\")\n",
        "print(f\"{'EfficientNet':<15} {effnet_f1*100:>6.2f}%         {effnet_status}\")\n",
        "\n",
        "print(f\"\\n Referencias esperadas (onsite test):\")\n",
        "print(f\"   ResNet18: {resnet_ref}%\")\n",
        "print(f\"   EfficientNet: {effnet_ref}%\")\n",
        "\n",
        "print(\"\\n Nota: Estos son resultados en offsite test.\")\n",
        "print(\"   Para onsite test, necesitas generar predicciones y submitir a Kaggle.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd4F7jHll_6E",
        "outputId": "7b7697d9-1a2d-4c6b-94b5-7fe9ae05062a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " RESUMEN TASK 1.1 - NO FINE-TUNING (Offsite Test Set)\n",
            "================================================================================\n",
            "\n",
            "Modelo          Avg F-score     Status              \n",
            "--------------------------------------------------\n",
            "ResNet18         51.26%          Bajo\n",
            "EfficientNet     55.41%          Bajo\n",
            "\n",
            " Referencias esperadas (onsite test):\n",
            "   ResNet18: 56.7%\n",
            "   EfficientNet: 60.4%\n",
            "\n",
            " Nota: Estos son resultados en offsite test.\n",
            "   Para onsite test, necesitas generar predicciones y submitir a Kaggle.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1.2"
      ],
      "metadata": {
        "id": "2tVplC5Wyma3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 1.2: FROZEN BACKBONE - FINE-TUNE CLASSIFIER ONLY\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ INICIANDO TASK 1.2: FROZEN BACKBONE - FINE-TUNE CLASSIFIER ONLY\")\n",
        "print(\"   Congelare el backbone y solo entrenar√© el clasificador final\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sj_eN8lyGkK",
        "outputId": "21b4875c-30d8-4ced-d8a0-adb53b9a77f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ INICIANDO TASK 1.2: FROZEN BACKBONE - FINE-TUNE CLASSIFIER ONLY\n",
            "   Congelare el backbone y solo entrenar√© el clasificador final\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n de entrenamiento\n",
        "# ============================================\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs, device, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Entrena un modelo y retorna el mejor seg√∫n validation loss.\n",
        "    \"\"\"\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    print(f\"\\n Iniciando entrenamiento de {model_name}\")\n",
        "    print(f\"   √âpocas: {num_epochs}\")\n",
        "    print(f\"   Device: {device}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ========================\n",
        "        # TRAINING\n",
        "        # ========================\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # ========================\n",
        "        # VALIDATION\n",
        "        # ========================\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}\", end=\"\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(\"  Best!\")\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\" Entrenamiento completado!\")\n",
        "    print(f\"   Best Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "print(\" Funci√≥n de entrenamiento definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ1rQ-ynyJ3Y",
        "outputId": "d47be8c4-1b01-48cf-faff-c7e338814163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n de entrenamiento definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Preparar datasets de Train y Val\n",
        "# ============================================\n",
        "\n",
        "print(\"üì¶ Preparando datasets de entrenamiento y validaci√≥n...\")\n",
        "\n",
        "# Paths\n",
        "train_csv = f\"{BASE_DIR}/train.csv\"\n",
        "val_csv = f\"{BASE_DIR}/val.csv\"\n",
        "train_dir = f\"{BASE_DIR}/images/train\"\n",
        "val_dir = f\"{BASE_DIR}/images/val\"\n",
        "\n",
        "# Transforms (con data augmentation para train)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Datasets\n",
        "train_ds = RetinaMultiLabelDataset(train_csv, train_dir, train_transform)\n",
        "val_ds = RetinaMultiLabelDataset(val_csv, val_dir, val_transform)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\" Datasets cargados:\")\n",
        "print(f\"   Train: {len(train_ds)} im√°genes\")\n",
        "print(f\"   Val:   {len(val_ds)} im√°genes\")\n",
        "print(f\"   Test:  {len(offsite_test_ds)} im√°genes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rIknBl-yRzD",
        "outputId": "fd095695-a2ab-4c26-d22e-661ab9e77052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Preparando datasets de entrenamiento y validaci√≥n...\n",
            " Datasets cargados:\n",
            "   Train: 800 im√°genes\n",
            "   Val:   200 im√°genes\n",
            "   Test:  200 im√°genes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.2 - ResNet18 - Frozen Backbone\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 1.2 - RESNET18 - FROZEN BACKBONE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "resnet_frozen = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_frozen.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. CONGELAR todas las capas del backbone\n",
        "for name, param in resnet_frozen.named_parameters():\n",
        "    if 'fc' not in name:  # Congelar todo excepto la capa final\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Verificar qu√© est√° congelado\n",
        "trainable_params = sum(p.numel() for p in resnet_frozen.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in resnet_frozen.parameters())\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "print(f\"   Frozen:     {total_params - trainable_params:,}\")\n",
        "\n",
        "# 3. Configurar entrenamiento\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_frozen.parameters()),\n",
        "                       lr=1e-3)  # Learning rate m√°s alto porque solo entrenamos classifier\n",
        "\n",
        "# 4. Entrenar\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "resnet_frozen_trained, train_losses, val_losses = train_model(\n",
        "    model=resnet_frozen,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 - Frozen Backbone\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkU_z1VfycnJ",
        "outputId": "d73e24a1-0072-4871-9f0b-2234fa088eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 1.2 - RESNET18 - FROZEN BACKBONE\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo pre-entrenado cargado\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      11,178,051\n",
            "   Trainable:  1,539 (0.01%)\n",
            "   Frozen:     11,176,512\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 - Frozen Backbone\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 1.2436 | Val Loss: 0.8297  Best!\n",
            "Epoch  2/20 | Train Loss: 0.6166 | Val Loss: 0.6110  Best!\n",
            "Epoch  3/20 | Train Loss: 0.5001 | Val Loss: 0.5738  Best!\n",
            "Epoch  4/20 | Train Loss: 0.4810 | Val Loss: 0.5421  Best!\n",
            "Epoch  5/20 | Train Loss: 0.4783 | Val Loss: 0.5359  Best!\n",
            "Epoch  6/20 | Train Loss: 0.4622 | Val Loss: 0.5442\n",
            "Epoch  7/20 | Train Loss: 0.4678 | Val Loss: 0.5288  Best!\n",
            "Epoch  8/20 | Train Loss: 0.4530 | Val Loss: 0.5428\n",
            "Epoch  9/20 | Train Loss: 0.4489 | Val Loss: 0.5099  Best!\n",
            "Epoch 10/20 | Train Loss: 0.4586 | Val Loss: 0.5178\n",
            "Epoch 11/20 | Train Loss: 0.4492 | Val Loss: 0.5174\n",
            "Epoch 12/20 | Train Loss: 0.4451 | Val Loss: 0.4957  Best!\n",
            "Epoch 13/20 | Train Loss: 0.4466 | Val Loss: 0.5042\n",
            "Epoch 14/20 | Train Loss: 0.4527 | Val Loss: 0.4897  Best!\n",
            "Epoch 15/20 | Train Loss: 0.4458 | Val Loss: 0.5192\n",
            "Epoch 16/20 | Train Loss: 0.4441 | Val Loss: 0.4977\n",
            "Epoch 17/20 | Train Loss: 0.4416 | Val Loss: 0.4887  Best!\n",
            "Epoch 18/20 | Train Loss: 0.4416 | Val Loss: 0.4873  Best!\n",
            "Epoch 19/20 | Train Loss: 0.4490 | Val Loss: 0.5071\n",
            "Epoch 20/20 | Train Loss: 0.4418 | Val Loss: 0.4769  Best!\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.4769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 - Frozen Backbone\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO RESNET18 - FROZEN BACKBONE\")\n",
        "\n",
        "resnet_frozen_results = evaluate_model(\n",
        "    resnet_frozen_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - Frozen Backbone - Offsite Test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLIZUVCRzDjx",
        "outputId": "113075f7-638e-48de-e4d7-9b7e17d2cc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO RESNET18 - FROZEN BACKBONE\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - Frozen Backbone - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.7975\n",
            "  Recall:    0.9000\n",
            "  F-score:   0.8456\n",
            "\n",
            "G:\n",
            "  Precision: 0.7619\n",
            "  Recall:    0.3265\n",
            "  F-score:   0.4571\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.8333\n",
            "  Recall:    0.2273\n",
            "  F-score:   0.3571\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.5533\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.2 - EfficientNet - Frozen Backbone\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 1.2 - EFFICIENTNET - FROZEN BACKBONE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "effnet_frozen = build_model(\"efficientnet\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "effnet_frozen.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_efficientnet_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. CONGELAR todas las capas del backbone\n",
        "for name, param in effnet_frozen.named_parameters():\n",
        "    if 'classifier' not in name:  # Congelar todo excepto classifier\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Verificar\n",
        "trainable_params = sum(p.numel() for p in effnet_frozen.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in effnet_frozen.parameters())\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "print(f\"   Frozen:     {total_params - trainable_params:,}\")\n",
        "\n",
        "# 3. Configurar entrenamiento\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, effnet_frozen.parameters()),\n",
        "                       lr=1e-3)\n",
        "\n",
        "# 4. Entrenar\n",
        "effnet_frozen_trained, train_losses_eff, val_losses_eff = train_model(\n",
        "    model=effnet_frozen,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"EfficientNet - Frozen Backbone\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmfEFNv7zMUF",
        "outputId": "86512371-2695-4cb4-fd69-27a9756d70ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 1.2 - EFFICIENTNET - FROZEN BACKBONE\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo pre-entrenado cargado\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      4,011,391\n",
            "   Trainable:  3,843 (0.10%)\n",
            "   Frozen:     4,007,548\n",
            "\n",
            " Iniciando entrenamiento de EfficientNet - Frozen Backbone\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 1.0841 | Val Loss: 0.6907  Best!\n",
            "Epoch  2/20 | Train Loss: 0.4826 | Val Loss: 0.5517  Best!\n",
            "Epoch  3/20 | Train Loss: 0.4341 | Val Loss: 0.4863  Best!\n",
            "Epoch  4/20 | Train Loss: 0.4034 | Val Loss: 0.4902\n",
            "Epoch  5/20 | Train Loss: 0.4013 | Val Loss: 0.4823  Best!\n",
            "Epoch  6/20 | Train Loss: 0.3858 | Val Loss: 0.4599  Best!\n",
            "Epoch  7/20 | Train Loss: 0.3879 | Val Loss: 0.4594  Best!\n",
            "Epoch  8/20 | Train Loss: 0.3705 | Val Loss: 0.4518  Best!\n",
            "Epoch  9/20 | Train Loss: 0.3802 | Val Loss: 0.4580\n",
            "Epoch 10/20 | Train Loss: 0.3650 | Val Loss: 0.4409  Best!\n",
            "Epoch 11/20 | Train Loss: 0.3587 | Val Loss: 0.4681\n",
            "Epoch 12/20 | Train Loss: 0.3576 | Val Loss: 0.4363  Best!\n",
            "Epoch 13/20 | Train Loss: 0.3519 | Val Loss: 0.4656\n",
            "Epoch 14/20 | Train Loss: 0.3580 | Val Loss: 0.4316  Best!\n",
            "Epoch 15/20 | Train Loss: 0.3610 | Val Loss: 0.4676\n",
            "Epoch 16/20 | Train Loss: 0.3440 | Val Loss: 0.4406\n",
            "Epoch 17/20 | Train Loss: 0.3592 | Val Loss: 0.4551\n",
            "Epoch 18/20 | Train Loss: 0.3539 | Val Loss: 0.4448\n",
            "Epoch 19/20 | Train Loss: 0.3446 | Val Loss: 0.4387\n",
            "Epoch 20/20 | Train Loss: 0.3426 | Val Loss: 0.4583\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.4316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar EfficientNet - Frozen Backbone\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO EFFICIENTNET - FROZEN BACKBONE\")\n",
        "\n",
        "effnet_frozen_results = evaluate_model(\n",
        "    effnet_frozen_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"EfficientNet - Frozen Backbone - Offsite Test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz5zjSZFzt12",
        "outputId": "491064cb-1c9f-47c1-bee3-4f199d082e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO EFFICIENTNET - FROZEN BACKBONE\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - EfficientNet - Frozen Backbone - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8235\n",
            "  Recall:    0.9000\n",
            "  F-score:   0.8601\n",
            "\n",
            "G:\n",
            "  Precision: 0.7419\n",
            "  Recall:    0.4694\n",
            "  F-score:   0.5750\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.8125\n",
            "  Recall:    0.5909\n",
            "  F-score:   0.6842\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.7064\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Comparaci√≥n Task 1.1 vs 1.2\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä COMPARACI√ìN TASK 1.1 vs TASK 1.2\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison_data = {\n",
        "    'ResNet18': {\n",
        "        'No Fine-tuning': task1_1_results['resnet18']['average_f1'] * 100,\n",
        "        'Frozen Backbone': resnet_frozen_results['average_f1'] * 100\n",
        "    },\n",
        "    'EfficientNet': {\n",
        "        'No Fine-tuning': task1_1_results['efficientnet']['average_f1'] * 100,\n",
        "        'Frozen Backbone': effnet_frozen_results['average_f1'] * 100\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"\\n{'Modelo':<15} {'Task 1.1':<15} {'Task 1.2':<15} {'Mejora':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for model_name, scores in comparison_data.items():\n",
        "    task11 = scores['No Fine-tuning']\n",
        "    task12 = scores['Frozen Backbone']\n",
        "    improvement = task12 - task11\n",
        "\n",
        "    print(f\"{model_name:<15} {task11:>6.2f}%        {task12:>6.2f}%        \"\n",
        "          f\"{'+' if improvement > 0 else ''}{improvement:>5.2f}%\")\n",
        "\n",
        "print(\"\\nüéØ Referencias Task 1.2 (onsite test):\")\n",
        "print(\"   ResNet18:     61.4%\")\n",
        "print(\"   EfficientNet: 73.5%\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "PAQLvlyczxxs",
        "outputId": "ce42f4d0-cdf2-4733-cd82-d57763a64b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä COMPARACI√ìN TASK 1.1 vs TASK 1.2\n",
            "================================================================================\n",
            "\n",
            "Modelo          Task 1.1        Task 1.2        Mejora         \n",
            "------------------------------------------------------------\n",
            "ResNet18         51.26%         55.33%        + 4.08%\n",
            "EfficientNet     55.41%         70.64%        +15.23%\n",
            "\n",
            "üéØ Referencias Task 1.2 (onsite test):\n",
            "   ResNet18:     61.4%\n",
            "   EfficientNet: 73.5%\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}