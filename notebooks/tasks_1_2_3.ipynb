{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XUjMNwGDGFl",
        "outputId": "64071a61-91f3-464e-f7bd-165b19b16241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'deep-learning-retinal-classification'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 29 (delta 12), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (29/29), 19.28 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "/content/deep-learning-retinal-classification\n",
            "‚úÖ Repositorio conectado!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive (opcional pero recomendado)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clonar tu repositorio\n",
        "GITHUB_USER = \"PieroCampos\"\n",
        "REPO_NAME = \"deep-learning-retinal-classification\"\n",
        "\n",
        "# Si es primera vez\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://github.com/PieroCampos/deep-learning-retinal-classification.git\n",
        "    %cd {REPO_NAME}\n",
        "else:\n",
        "    %cd {REPO_NAME}\n",
        "    !git pull\n",
        "\n",
        "print(\"‚úÖ Repositorio conectado!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalar dependencias\n",
        "\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q timm  # Para modelos pre-entrenados\n",
        "!pip install -q scikit-learn pandas matplotlib seaborn\n",
        "!pip install -q kaggle  # Para descargar dataset"
      ],
      "metadata": {
        "id": "1DRSNt67G2-r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 3: Montar Google Drive\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "\n",
        "print(\" Montando Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n Google Drive montado!\")\n",
        "print(\"\\n Verificando archivos en Drive...\")\n",
        "\n",
        "# Listar contenido de tu carpeta del proyecto\n",
        "!ls -lh \"/content/drive/MyDrive/DL_Project_ODIR/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-20RC-jSwRT",
        "outputId": "fd513380-abb3-44cf-cdfe-5175ab9ee7e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Montando Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            " Google Drive montado!\n",
            "\n",
            " Verificando archivos en Drive...\n",
            "total 64M\n",
            "-rw------- 1 root root  64M Dec 28 23:27  final-project-deep-learning-fall-2025.zip\n",
            "drwx------ 2 root root 4.0K Dec 29 14:03 'Oulu University'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 4: Extraer dataset desde Google Drive\n",
        "# ============================================\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Crear directorio para datos\n",
        "!mkdir -p ./data\n",
        "\n",
        "# Ruta al archivo ZIP en tu Drive\n",
        "zip_path = \"/content/drive/MyDrive/DL_Project_ODIR/final-project-deep-learning-fall-2025.zip\"\n",
        "\n",
        "# Verificar que existe\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\" Archivo encontrado: {zip_path}\")\n",
        "    print(f\" Tama√±o: {os.path.getsize(zip_path) / (1024*1024):.2f} MB\")\n",
        "    print(\"\\n Descomprimiendo... (esto puede tomar 2-3 minutos)\")\n",
        "\n",
        "    # Descomprimir\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('./data')\n",
        "\n",
        "    print(\"\\n ¬°Dataset extra√≠do correctamente!\")\n",
        "\n",
        "else:\n",
        "    print(f\" No se encontr√≥ el archivo en: {zip_path}\")\n",
        "    print(\"\\n Archivos disponibles en tu carpeta:\")\n",
        "    !ls \"/content/drive/MyDrive/DL_Project_ODIR/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6kTdO9FT_sj",
        "outputId": "55d29ea8-7a6c-4bc9-8581-c94098279d31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Archivo encontrado: /content/drive/MyDrive/DL_Project_ODIR/final-project-deep-learning-fall-2025.zip\n",
            " Tama√±o: 63.10 MB\n",
            "\n",
            " Descomprimiendo... (esto puede tomar 2-3 minutos)\n",
            "\n",
            " ¬°Dataset extra√≠do correctamente!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Verificar estructura del dataset\n",
        "# ============================================\n",
        "import os\n",
        "\n",
        "print(\" ESTRUCTURA DEL DATASET:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Funci√≥n para mostrar √°rbol de directorios\n",
        "def show_tree(path, prefix=\"\", max_files=10):\n",
        "    try:\n",
        "        items = sorted(os.listdir(path))\n",
        "        dirs = [i for i in items if os.path.isdir(os.path.join(path, i))]\n",
        "        files = [i for i in items if os.path.isfile(os.path.join(path, i))]\n",
        "\n",
        "        # Mostrar directorios\n",
        "        for d in dirs:\n",
        "            print(f\"{prefix}üìÅ {d}/\")\n",
        "            show_tree(os.path.join(path, d), prefix + \"  \", max_files)\n",
        "\n",
        "        # Mostrar archivos\n",
        "        for i, f in enumerate(files):\n",
        "            if i < max_files:\n",
        "                size = os.path.getsize(os.path.join(path, f))\n",
        "                size_str = f\"{size/1024:.1f} KB\" if size < 1024*1024 else f\"{size/(1024*1024):.1f} MB\"\n",
        "                print(f\"{prefix}üìÑ {f} ({size_str})\")\n",
        "            elif i == max_files:\n",
        "                print(f\"{prefix}   ... y {len(files) - max_files} archivos m√°s\")\n",
        "                break\n",
        "\n",
        "    except PermissionError:\n",
        "        print(f\"{prefix} Sin permisos\")\n",
        "\n",
        "show_tree('./data')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Contar im√°genes si existen\n",
        "if os.path.exists('./data/images'):\n",
        "    num_images = len([f for f in os.listdir('./data/images') if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    print(f\"üì∏ Total de im√°genes encontradas: {num_images}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcIzmDFAUS01",
        "outputId": "dcb71a24-057b-4f52-bcfb-11616b6ebd20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ESTRUCTURA DEL DATASET:\n",
            "============================================================\n",
            "üìÅ final_project_resources/\n",
            "  üìÅ .idea/\n",
            "    üìÅ inspectionProfiles/\n",
            "      üìÑ profiles_settings.xml (0.2 KB)\n",
            "    üìÑ .gitignore (0.0 KB)\n",
            "    üìÑ final_project_resources.iml (0.3 KB)\n",
            "    üìÑ misc.xml (0.3 KB)\n",
            "    üìÑ modules.xml (0.3 KB)\n",
            "    üìÑ workspace.xml (2.0 KB)\n",
            "  üìÅ images/\n",
            "    üìÅ offsite_test/\n",
            "      üìÑ 102_left.jpg (7.3 KB)\n",
            "      üìÑ 1071_left.jpg (7.4 KB)\n",
            "      üìÑ 1147_right.jpg (8.5 KB)\n",
            "      üìÑ 1210_left.jpg (5.1 KB)\n",
            "      üìÑ 1212_left.jpg (6.4 KB)\n",
            "      üìÑ 1221_right.jpg (4.5 KB)\n",
            "      üìÑ 1229_left.jpg (5.2 KB)\n",
            "      üìÑ 1234_left.jpg (6.6 KB)\n",
            "      üìÑ 1237_right.jpg (6.3 KB)\n",
            "      üìÑ 1239_left.jpg (6.2 KB)\n",
            "         ... y 190 archivos m√°s\n",
            "    üìÅ onsite_test/\n",
            "      üìÑ 1022_left.jpg (5.6 KB)\n",
            "      üìÑ 1022_right.jpg (5.3 KB)\n",
            "      üìÑ 102_right.jpg (7.8 KB)\n",
            "      üìÑ 1071_right.jpg (7.5 KB)\n",
            "      üìÑ 1082_right.jpg (6.8 KB)\n",
            "      üìÑ 1138_right.jpg (5.8 KB)\n",
            "      üìÑ 1157_right.jpg (7.3 KB)\n",
            "      üìÑ 1167_right.jpg (5.0 KB)\n",
            "      üìÑ 1196_right.jpg (6.7 KB)\n",
            "      üìÑ 11_left.jpg (7.2 KB)\n",
            "         ... y 240 archivos m√°s\n",
            "    üìÅ train/\n",
            "      üìÑ 1020_left.jpg (6.9 KB)\n",
            "      üìÑ 1035_right.jpg (8.9 KB)\n",
            "      üìÑ 1043_right.jpg (6.1 KB)\n",
            "      üìÑ 1064_left.jpg (6.8 KB)\n",
            "      üìÑ 1065_left.jpg (8.1 KB)\n",
            "      üìÑ 1075_left.jpg (6.5 KB)\n",
            "      üìÑ 1083_left.jpg (4.9 KB)\n",
            "      üìÑ 1084_left.jpg (6.7 KB)\n",
            "      üìÑ 1084_right.jpg (5.5 KB)\n",
            "      üìÑ 1085_right.jpg (7.6 KB)\n",
            "         ... y 790 archivos m√°s\n",
            "    üìÅ val/\n",
            "      üìÑ 1043_left.jpg (5.8 KB)\n",
            "      üìÑ 1064_right.jpg (6.9 KB)\n",
            "      üìÑ 1068_left.jpg (7.7 KB)\n",
            "      üìÑ 107_right.jpg (6.7 KB)\n",
            "      üìÑ 1083_right.jpg (5.4 KB)\n",
            "      üìÑ 1085_left.jpg (7.6 KB)\n",
            "      üìÑ 1091_left.jpg (6.9 KB)\n",
            "      üìÑ 1098_left.jpg (6.2 KB)\n",
            "      üìÑ 1125_right.jpg (7.1 KB)\n",
            "      üìÑ 1147_left.jpg (8.6 KB)\n",
            "         ... y 190 archivos m√°s\n",
            "  üìÅ pretrained_backbone/\n",
            "    üìÑ ckpt_efficientnet_ep50.pt (15.6 MB)\n",
            "    üìÑ ckpt_resnet18_ep50.pt (42.7 MB)\n",
            "  üìÑ code_template.py (6.7 KB)\n",
            "  üìÑ offsite_test.csv (4.0 KB)\n",
            "  üìÑ onsite_test_submission.csv (5.2 KB)\n",
            "  üìÑ train.csv (15.8 KB)\n",
            "  üìÑ val.csv (3.9 KB)\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 6: Verificar archivos CSV\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "\n",
        "print(\" VERIFICANDO ARCHIVOS CSV:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Lista de archivos esperados\n",
        "csv_files = {\n",
        "    'train.csv': './data/final_project_resources/train.csv',\n",
        "    'val.csv': './data/final_project_resources/val.csv',\n",
        "    'offsite_test.csv': './data/final_project_resources/offsite_test.csv',\n",
        "    'onsite_test_submission.csv': './data/final_project_resources/onsite_test_submission.csv'\n",
        "}\n",
        "\n",
        "for name, path in csv_files.items():\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"\\n** {name}\")\n",
        "        print(f\"   Filas: {len(df)}\")\n",
        "        print(f\"   Columnas: {list(df.columns)}\")\n",
        "        print(f\"   Primeras filas:\")\n",
        "        print(df.head(2).to_string(index=False))\n",
        "    else:\n",
        "        print(f\"\\n‚ùå {name} - NO ENCONTRADO\")\n",
        "        print(f\"   Buscando en: {path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sCMhcBGUost",
        "outputId": "69bc270d-565b-4a8a-e255-be0d06ab7a0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " VERIFICANDO ARCHIVOS CSV:\n",
            "============================================================\n",
            "\n",
            "** train.csv\n",
            "   Filas: 800\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "           id  D  G  A\n",
            "913_right.jpg  1  0  0\n",
            " 281_left.jpg  1  0  0\n",
            "\n",
            "** val.csv\n",
            "   Filas: 200\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "           id  D  G  A\n",
            "184_right.jpg  1  0  0\n",
            "4488_left.jpg  1  0  0\n",
            "\n",
            "** offsite_test.csv\n",
            "   Filas: 200\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "           id  D  G  A\n",
            "568_right.jpg  1  0  0\n",
            " 748_left.jpg  1  0  0\n",
            "\n",
            "** onsite_test_submission.csv\n",
            "   Filas: 250\n",
            "   Columnas: ['id', 'D', 'G', 'A']\n",
            "   Primeras filas:\n",
            "            id  D  G  A\n",
            "4595_right.jpg  0  0  0\n",
            " 4155_left.jpg  0  0  0\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1.1"
      ],
      "metadata": {
        "id": "UUMIP9mwysyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 1: TRANSFER LEARNING\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" INICIANDO TASK 1: TRANSFER LEARNING\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr2cQYUJjG8i",
        "outputId": "b2dd7e18-ca57-44d5-8bd6-b88db20feafe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " INICIANDO TASK 1: TRANSFER LEARNING\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Importar librer√≠as necesarias para Task 1\n",
        "# ============================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "print(\" Librer√≠as importadas!\")\n",
        "print(f\" Device disponible: {'GPU ' if torch.cuda.is_available() else 'CPU '}\")\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1G0tXPyjP0e",
        "outputId": "802dd376-6eaa-42f2-b078-df153414e1da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Librer√≠as importadas!\n",
            " Device disponible: GPU \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Clase Dataset (Multi-label)\n",
        "# ============================================\n",
        "class RetinaMultiLabelDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row.iloc[0])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        labels = torch.tensor(row[1:].values.astype(\"float32\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, labels\n",
        "\n",
        "print(\" Clase Dataset definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQTniocljfG2",
        "outputId": "4f2cb443-4933-4813-bb07-706eaee3e952"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Clase Dataset definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n para construir modelos\n",
        "# ============================================\n",
        "def build_model(backbone=\"resnet18\", num_classes=3, pretrained=False):\n",
        "    \"\"\"\n",
        "    Construye un modelo con el backbone especificado.\n",
        "\n",
        "    Args:\n",
        "        backbone: 'resnet18' o 'efficientnet'\n",
        "        num_classes: n√∫mero de clases (3 para DR, G, AMD)\n",
        "        pretrained: usar pesos de ImageNet (no usado aqu√≠)\n",
        "    \"\"\"\n",
        "    if backbone == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif backbone == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(pretrained=pretrained)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Backbone no soportado: {backbone}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\" Funci√≥n build_model definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8OKvF5jm5t",
        "outputId": "e039f063-1990-4187-83ce-5353fec63b79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n build_model definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n de evaluaci√≥n\n",
        "# ============================================\n",
        "def evaluate_model(model, test_loader, device, dataset_name=\"Test\"):\n",
        "    \"\"\"\n",
        "    Eval√∫a un modelo y retorna m√©tricas por enfermedad.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    disease_names = [\"DR\", \"G\", \"AMD\"]\n",
        "    results = {}\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" RESULTADOS - {dataset_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    f_scores = []\n",
        "    for i, disease in enumerate(disease_names):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        precision = precision_score(y_t, y_p, zero_division=0)\n",
        "        recall = recall_score(y_t, y_p, zero_division=0)\n",
        "        f1 = f1_score(y_t, y_p, zero_division=0)\n",
        "\n",
        "        results[disease] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "\n",
        "        f_scores.append(f1)\n",
        "\n",
        "        print(f\"\\n{disease}:\")\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "        print(f\"  Recall:    {recall:.4f}\")\n",
        "        print(f\"  F-score:   {f1:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(f_scores)\n",
        "    results['average_f1'] = avg_f1\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\" AVERAGE F-SCORE: {avg_f1:.4f}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\" Funci√≥n evaluate_model definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aEYihJNjttK",
        "outputId": "046f4c8e-bfb1-408c-fe14-365abddf4c50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n evaluate_model definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.1 - No Fine-tuning\n",
        "# Evaluar modelos pre-entrenados sin modificaci√≥n\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" TASK 1.1: NO FINE-TUNING\")\n",
        "print(\"   Evaluando modelos pre-entrenados directamente en ODIR test set\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Configuraci√≥n de rutas\n",
        "BASE_DIR = \"./data/final_project_resources\"\n",
        "offsite_test_csv = f\"{BASE_DIR}/offsite_test.csv\"\n",
        "offsite_test_dir = f\"{BASE_DIR}/images/offsite_test\"\n",
        "\n",
        "# Transform (mismo que se us√≥ en pre-entrenamiento)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Crear dataset y dataloader para offsite test\n",
        "offsite_test_ds = RetinaMultiLabelDataset(\n",
        "    offsite_test_csv,\n",
        "    offsite_test_dir,\n",
        "    transform\n",
        ")\n",
        "\n",
        "offsite_test_loader = DataLoader(\n",
        "    offsite_test_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\" Offsite test set cargado: {len(offsite_test_ds)} im√°genes\\n\")\n",
        "\n",
        "# Almacenar resultados\n",
        "task1_1_results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXJA5n_6j5Ga",
        "outputId": "e5dc9ad2-d2ad-4dac-8eaf-00888029f0c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " TASK 1.1: NO FINE-TUNING\n",
            "   Evaluando modelos pre-entrenados directamente en ODIR test set\n",
            "================================================================================\n",
            "\n",
            " Offsite test set cargado: 200 im√°genes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18\n",
        "# ========================\n",
        "print(\" EVALUANDO RESNET18\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "resnet_model = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_pretrained_path = f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\"\n",
        "\n",
        "# Cargar pesos pre-entrenados\n",
        "state_dict = torch.load(resnet_pretrained_path, map_location=DEVICE)\n",
        "resnet_model.load_state_dict(state_dict)\n",
        "\n",
        "print(f\" Pesos cargados desde: {resnet_pretrained_path}\\n\")\n",
        "\n",
        "# Evaluar\n",
        "resnet_results = evaluate_model(\n",
        "    resnet_model,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - No Fine-tuning - Offsite Test\"\n",
        ")\n",
        "\n",
        "task1_1_results['resnet18'] = resnet_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fK0sGjFkFOM",
        "outputId": "0b627707-3332-4e17-fb14-cfdeecc4909a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " EVALUANDO RESNET18\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pesos cargados desde: ./data/final_project_resources/pretrained_backbone/ckpt_resnet18_ep50.pt\n",
            "\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - No Fine-tuning - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.7172\n",
            "  Recall:    0.5071\n",
            "  F-score:   0.5941\n",
            "\n",
            "G:\n",
            "  Precision: 0.5750\n",
            "  Recall:    0.4694\n",
            "  F-score:   0.5169\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.3019\n",
            "  Recall:    0.7273\n",
            "  F-score:   0.4267\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.5126\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar EfficientNet\n",
        "# ========================\n",
        "print(\"\\n EVALUANDO EFFICIENTNET\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "effnet_model = build_model(\"efficientnet\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "effnet_pretrained_path = f\"{BASE_DIR}/pretrained_backbone/ckpt_efficientnet_ep50.pt\"\n",
        "\n",
        "# Cargar pesos pre-entrenados\n",
        "state_dict = torch.load(effnet_pretrained_path, map_location=DEVICE)\n",
        "effnet_model.load_state_dict(state_dict)\n",
        "\n",
        "print(f\" Pesos cargados desde: {effnet_pretrained_path}\\n\")\n",
        "\n",
        "# Evaluar\n",
        "effnet_results = evaluate_model(\n",
        "    effnet_model,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"EfficientNet - No Fine-tuning - Offsite Test\"\n",
        ")\n",
        "\n",
        "task1_1_results['efficientnet'] = effnet_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJoVVu_lllGI",
        "outputId": "e8110515-3895-42e2-dcaf-a194ae645f19"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO EFFICIENTNET\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pesos cargados desde: ./data/final_project_resources/pretrained_backbone/ckpt_efficientnet_ep50.pt\n",
            "\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - EfficientNet - No Fine-tuning - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.7459\n",
            "  Recall:    0.6500\n",
            "  F-score:   0.6947\n",
            "\n",
            "G:\n",
            "  Precision: 0.5769\n",
            "  Recall:    0.6122\n",
            "  F-score:   0.5941\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.2464\n",
            "  Recall:    0.7727\n",
            "  F-score:   0.3736\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.5541\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Resumen Task 1.1\n",
        "# ========================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN TASK 1.1 - NO FINE-TUNING (Offsite Test Set)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Modelo':<15} {'Avg F-score':<15} {'Status':<20}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "resnet_f1 = task1_1_results['resnet18']['average_f1']\n",
        "effnet_f1 = task1_1_results['efficientnet']['average_f1']\n",
        "\n",
        "# Comparar con referencias\n",
        "resnet_ref = 56.7\n",
        "effnet_ref = 60.4\n",
        "\n",
        "resnet_status = \" Comparable\" if resnet_f1 >= resnet_ref * 0.9 else \" Bajo\"\n",
        "effnet_status = \" Comparable\" if effnet_f1 >= effnet_ref * 0.9 else \" Bajo\"\n",
        "\n",
        "print(f\"{'ResNet18':<15} {resnet_f1*100:>6.2f}%         {resnet_status}\")\n",
        "print(f\"{'EfficientNet':<15} {effnet_f1*100:>6.2f}%         {effnet_status}\")\n",
        "\n",
        "print(f\"\\n Referencias esperadas (onsite test):\")\n",
        "print(f\"   ResNet18: {resnet_ref}%\")\n",
        "print(f\"   EfficientNet: {effnet_ref}%\")\n",
        "\n",
        "print(\"\\n Nota: Estos son resultados en offsite test.\")\n",
        "print(\"   Para onsite test, necesitas generar predicciones y submitir a Kaggle.\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd4F7jHll_6E",
        "outputId": "0bc8e369-389f-4b97-e095-a8aa55659a7a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " RESUMEN TASK 1.1 - NO FINE-TUNING (Offsite Test Set)\n",
            "================================================================================\n",
            "\n",
            "Modelo          Avg F-score     Status              \n",
            "--------------------------------------------------\n",
            "ResNet18         51.26%          Bajo\n",
            "EfficientNet     55.41%          Bajo\n",
            "\n",
            " Referencias esperadas (onsite test):\n",
            "   ResNet18: 56.7%\n",
            "   EfficientNet: 60.4%\n",
            "\n",
            " Nota: Estos son resultados en offsite test.\n",
            "   Para onsite test, necesitas generar predicciones y submitir a Kaggle.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1.2"
      ],
      "metadata": {
        "id": "2tVplC5Wyma3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 1.2: FROZEN BACKBONE - FINE-TUNE CLASSIFIER ONLY\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ INICIANDO TASK 1.2: FROZEN BACKBONE - FINE-TUNE CLASSIFIER ONLY\")\n",
        "print(\"   Congelare el backbone y solo entrenar√© el clasificador final\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sj_eN8lyGkK",
        "outputId": "eaccfdc3-21e3-4310-fe27-48adef9e8f51"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ INICIANDO TASK 1.2: FROZEN BACKBONE - FINE-TUNE CLASSIFIER ONLY\n",
            "   Congelare el backbone y solo entrenar√© el clasificador final\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n de entrenamiento\n",
        "# ============================================\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs, device, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Entrena un modelo y retorna el mejor seg√∫n validation loss.\n",
        "    \"\"\"\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    print(f\"\\n Iniciando entrenamiento de {model_name}\")\n",
        "    print(f\"   √âpocas: {num_epochs}\")\n",
        "    print(f\"   Device: {device}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ========================\n",
        "        # TRAINING\n",
        "        # ========================\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # ========================\n",
        "        # VALIDATION\n",
        "        # ========================\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}\", end=\"\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(\"  Best!\")\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\" Entrenamiento completado!\")\n",
        "    print(f\"   Best Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "print(\" Funci√≥n de entrenamiento definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ1rQ-ynyJ3Y",
        "outputId": "0a74e43a-a9e4-40c7-dd3a-08e822901ff5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n de entrenamiento definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Preparar datasets de Train y Val\n",
        "# ============================================\n",
        "\n",
        "print(\"üì¶ Preparando datasets de entrenamiento y validaci√≥n...\")\n",
        "\n",
        "# Paths\n",
        "train_csv = f\"{BASE_DIR}/train.csv\"\n",
        "val_csv = f\"{BASE_DIR}/val.csv\"\n",
        "train_dir = f\"{BASE_DIR}/images/train\"\n",
        "val_dir = f\"{BASE_DIR}/images/val\"\n",
        "\n",
        "# Transforms (con data augmentation para train)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Datasets\n",
        "train_ds = RetinaMultiLabelDataset(train_csv, train_dir, train_transform)\n",
        "val_ds = RetinaMultiLabelDataset(val_csv, val_dir, val_transform)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\" Datasets cargados:\")\n",
        "print(f\"   Train: {len(train_ds)} im√°genes\")\n",
        "print(f\"   Val:   {len(val_ds)} im√°genes\")\n",
        "print(f\"   Test:  {len(offsite_test_ds)} im√°genes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rIknBl-yRzD",
        "outputId": "dfbe98ae-d716-44d0-da29-33bdd3d94133"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Preparando datasets de entrenamiento y validaci√≥n...\n",
            " Datasets cargados:\n",
            "   Train: 800 im√°genes\n",
            "   Val:   200 im√°genes\n",
            "   Test:  200 im√°genes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.2 - ResNet18 - Frozen Backbone\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 1.2 - RESNET18 - FROZEN BACKBONE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "resnet_frozen = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_frozen.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. CONGELAR todas las capas del backbone\n",
        "for name, param in resnet_frozen.named_parameters():\n",
        "    if 'fc' not in name:  # Congelar todo excepto la capa final\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Verificar qu√© est√° congelado\n",
        "trainable_params = sum(p.numel() for p in resnet_frozen.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in resnet_frozen.parameters())\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "print(f\"   Frozen:     {total_params - trainable_params:,}\")\n",
        "\n",
        "# 3. Configurar entrenamiento\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, resnet_frozen.parameters()),\n",
        "                       lr=1e-3)  # Learning rate m√°s alto porque solo entrenamos classifier\n",
        "\n",
        "# 4. Entrenar\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "resnet_frozen_trained, train_losses, val_losses = train_model(\n",
        "    model=resnet_frozen,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 - Frozen Backbone\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkU_z1VfycnJ",
        "outputId": "b1cbff63-201c-4090-a133-32b65d780b8c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 1.2 - RESNET18 - FROZEN BACKBONE\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo pre-entrenado cargado\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      11,178,051\n",
            "   Trainable:  1,539 (0.01%)\n",
            "   Frozen:     11,176,512\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 - Frozen Backbone\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 1.2138 | Val Loss: 0.7931  Best!\n",
            "Epoch  2/20 | Train Loss: 0.6450 | Val Loss: 0.6006  Best!\n",
            "Epoch  3/20 | Train Loss: 0.4862 | Val Loss: 0.5514  Best!\n",
            "Epoch  4/20 | Train Loss: 0.4892 | Val Loss: 0.5652\n",
            "Epoch  5/20 | Train Loss: 0.4757 | Val Loss: 0.5406  Best!\n",
            "Epoch  6/20 | Train Loss: 0.4633 | Val Loss: 0.5403  Best!\n",
            "Epoch  7/20 | Train Loss: 0.4709 | Val Loss: 0.5066  Best!\n",
            "Epoch  8/20 | Train Loss: 0.4517 | Val Loss: 0.5188\n",
            "Epoch  9/20 | Train Loss: 0.4677 | Val Loss: 0.5346\n",
            "Epoch 10/20 | Train Loss: 0.4547 | Val Loss: 0.5185\n",
            "Epoch 11/20 | Train Loss: 0.4638 | Val Loss: 0.5094\n",
            "Epoch 12/20 | Train Loss: 0.4604 | Val Loss: 0.5323\n",
            "Epoch 13/20 | Train Loss: 0.4484 | Val Loss: 0.5155\n",
            "Epoch 14/20 | Train Loss: 0.4647 | Val Loss: 0.4931  Best!\n",
            "Epoch 15/20 | Train Loss: 0.4398 | Val Loss: 0.4884  Best!\n",
            "Epoch 16/20 | Train Loss: 0.4424 | Val Loss: 0.5171\n",
            "Epoch 17/20 | Train Loss: 0.4377 | Val Loss: 0.5098\n",
            "Epoch 18/20 | Train Loss: 0.4285 | Val Loss: 0.4887\n",
            "Epoch 19/20 | Train Loss: 0.4414 | Val Loss: 0.4886\n",
            "Epoch 20/20 | Train Loss: 0.4359 | Val Loss: 0.5051\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.4884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 - Frozen Backbone\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO RESNET18 - FROZEN BACKBONE\")\n",
        "\n",
        "resnet_frozen_results = evaluate_model(\n",
        "    resnet_frozen_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - Frozen Backbone - Offsite Test\"\n",
        ")"
      ],
      "metadata": {
        "id": "gLIZUVCRzDjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9c1da8-414b-43cf-c1f7-0a254127fb81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO RESNET18 - FROZEN BACKBONE\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - Frozen Backbone - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.7733\n",
            "  Recall:    0.9500\n",
            "  F-score:   0.8526\n",
            "\n",
            "G:\n",
            "  Precision: 0.8889\n",
            "  Recall:    0.1633\n",
            "  F-score:   0.2759\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.7500\n",
            "  Recall:    0.1364\n",
            "  F-score:   0.2308\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.4531\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.2 - EfficientNet - Frozen Backbone\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 1.2 - EFFICIENTNET - FROZEN BACKBONE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "effnet_frozen = build_model(\"efficientnet\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "effnet_frozen.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_efficientnet_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. CONGELAR todas las capas del backbone\n",
        "for name, param in effnet_frozen.named_parameters():\n",
        "    if 'classifier' not in name:  # Congelar todo excepto classifier\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Verificar\n",
        "trainable_params = sum(p.numel() for p in effnet_frozen.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in effnet_frozen.parameters())\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "print(f\"   Frozen:     {total_params - trainable_params:,}\")\n",
        "\n",
        "# 3. Configurar entrenamiento\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, effnet_frozen.parameters()),\n",
        "                       lr=1e-3)\n",
        "\n",
        "# 4. Entrenar\n",
        "effnet_frozen_trained, train_losses_eff, val_losses_eff = train_model(\n",
        "    model=effnet_frozen,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"EfficientNet - Frozen Backbone\"\n",
        ")"
      ],
      "metadata": {
        "id": "lmfEFNv7zMUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c6128a-05ec-4f32-9149-915e6f59bd63"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 1.2 - EFFICIENTNET - FROZEN BACKBONE\n",
            "================================================================================\n",
            "‚úÖ Modelo pre-entrenado cargado\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      4,011,391\n",
            "   Trainable:  3,843 (0.10%)\n",
            "   Frozen:     4,007,548\n",
            "\n",
            " Iniciando entrenamiento de EfficientNet - Frozen Backbone\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/20 | Train Loss: 1.0481 | Val Loss: 0.7278  Best!\n",
            "Epoch  2/20 | Train Loss: 0.4829 | Val Loss: 0.5484  Best!\n",
            "Epoch  3/20 | Train Loss: 0.4373 | Val Loss: 0.4983  Best!\n",
            "Epoch  4/20 | Train Loss: 0.4040 | Val Loss: 0.4753  Best!\n",
            "Epoch  5/20 | Train Loss: 0.3943 | Val Loss: 0.4991\n",
            "Epoch  6/20 | Train Loss: 0.3958 | Val Loss: 0.4643  Best!\n",
            "Epoch  7/20 | Train Loss: 0.3816 | Val Loss: 0.4570  Best!\n",
            "Epoch  8/20 | Train Loss: 0.3920 | Val Loss: 0.4430  Best!\n",
            "Epoch  9/20 | Train Loss: 0.3616 | Val Loss: 0.4709\n",
            "Epoch 10/20 | Train Loss: 0.3569 | Val Loss: 0.4423  Best!\n",
            "Epoch 11/20 | Train Loss: 0.3713 | Val Loss: 0.4614\n",
            "Epoch 12/20 | Train Loss: 0.3523 | Val Loss: 0.4479\n",
            "Epoch 13/20 | Train Loss: 0.3699 | Val Loss: 0.4305  Best!\n",
            "Epoch 14/20 | Train Loss: 0.3590 | Val Loss: 0.4510\n",
            "Epoch 15/20 | Train Loss: 0.3534 | Val Loss: 0.4608\n",
            "Epoch 16/20 | Train Loss: 0.3523 | Val Loss: 0.4507\n",
            "Epoch 17/20 | Train Loss: 0.3411 | Val Loss: 0.4343\n",
            "Epoch 18/20 | Train Loss: 0.3355 | Val Loss: 0.4320\n",
            "Epoch 19/20 | Train Loss: 0.3429 | Val Loss: 0.4416\n",
            "Epoch 20/20 | Train Loss: 0.3402 | Val Loss: 0.4321\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.4305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar EfficientNet - Frozen Backbone\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO EFFICIENTNET - FROZEN BACKBONE\")\n",
        "\n",
        "effnet_frozen_results = evaluate_model(\n",
        "    effnet_frozen_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"EfficientNet - Frozen Backbone - Offsite Test\"\n",
        ")"
      ],
      "metadata": {
        "id": "jz5zjSZFzt12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8a22ef-fd08-4b74-e303-f1ac96e7e56b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO EFFICIENTNET - FROZEN BACKBONE\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - EfficientNet - Frozen Backbone - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8561\n",
            "  Recall:    0.8500\n",
            "  F-score:   0.8530\n",
            "\n",
            "G:\n",
            "  Precision: 0.7353\n",
            "  Recall:    0.5102\n",
            "  F-score:   0.6024\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.7647\n",
            "  Recall:    0.5909\n",
            "  F-score:   0.6667\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.7074\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Comparaci√≥n Task 1.1 vs 1.2\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä COMPARACI√ìN TASK 1.1 vs TASK 1.2\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "comparison_data = {\n",
        "    'ResNet18': {\n",
        "        'No Fine-tuning': task1_1_results['resnet18']['average_f1'] * 100,\n",
        "        'Frozen Backbone': resnet_frozen_results['average_f1'] * 100\n",
        "    },\n",
        "    'EfficientNet': {\n",
        "        'No Fine-tuning': task1_1_results['efficientnet']['average_f1'] * 100,\n",
        "        'Frozen Backbone': effnet_frozen_results['average_f1'] * 100\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"\\n{'Modelo':<15} {'Task 1.1':<15} {'Task 1.2':<15} {'Mejora':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for model_name, scores in comparison_data.items():\n",
        "    task11 = scores['No Fine-tuning']\n",
        "    task12 = scores['Frozen Backbone']\n",
        "    improvement = task12 - task11\n",
        "\n",
        "    print(f\"{model_name:<15} {task11:>6.2f}%        {task12:>6.2f}%        \"\n",
        "          f\"{'+' if improvement > 0 else ''}{improvement:>5.2f}%\")\n",
        "\n",
        "print(\"\\nüéØ Referencias Task 1.2 (onsite test):\")\n",
        "print(\"   ResNet18:     61.4%\")\n",
        "print(\"   EfficientNet: 73.5%\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "PAQLvlyczxxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824cfdaf-7053-474b-f200-cc1395165611"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä COMPARACI√ìN TASK 1.1 vs TASK 1.2\n",
            "================================================================================\n",
            "\n",
            "Modelo          Task 1.1        Task 1.2        Mejora         \n",
            "------------------------------------------------------------\n",
            "ResNet18         51.26%         45.31%        -5.95%\n",
            "EfficientNet     55.41%         70.74%        +15.33%\n",
            "\n",
            "üéØ Referencias Task 1.2 (onsite test):\n",
            "   ResNet18:     61.4%\n",
            "   EfficientNet: 73.5%\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1.3"
      ],
      "metadata": {
        "id": "QP5TLA-WSCpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 1.3: FULL FINE-TUNING\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" INICIANDO TASK 1.3: FULL FINE-TUNING\")\n",
        "print(\"   Entrenando TODO el modelo (backbone + classifier)\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2M4zrOnfTl0",
        "outputId": "d0f95c99-443d-4d29-899f-c2155f9d4363"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " INICIANDO TASK 1.3: FULL FINE-TUNING\n",
            "   Entrenando TODO el modelo (backbone + classifier)\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.3 - ResNet18 - Full Fine-tuning\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 1.3 - RESNET18 - FULL FINE-TUNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado (empezamos desde los pesos originales)\n",
        "resnet_full = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_full.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. DESCONGELAR TODO - entrenar todas las capas\n",
        "for param in resnet_full.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Verificar\n",
        "trainable_params = sum(p.numel() for p in resnet_full.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in resnet_full.parameters())\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "\n",
        "# 3. Configurar entrenamiento con LR M√ÅS BAJO\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(resnet_full.parameters(), lr=1e-4)  # ‚Üê LR m√°s bajo\n",
        "\n",
        "# 4. Entrenar\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "resnet_full_trained, train_losses_full, val_losses_full = train_model(\n",
        "    model=resnet_full,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 - Full Fine-tuning\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWcjdEPofXmA",
        "outputId": "6dc83111-2284-4758-a9fd-fd99dd6a2ebc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 1.3 - RESNET18 - FULL FINE-TUNING\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo pre-entrenado cargado\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      11,178,051\n",
            "   Trainable:  11,178,051 (100.00%)\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 - Full Fine-tuning\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 0.7860 | Val Loss: 0.6476  Best!\n",
            "Epoch  2/20 | Train Loss: 0.3865 | Val Loss: 0.4457  Best!\n",
            "Epoch  3/20 | Train Loss: 0.2939 | Val Loss: 0.4134  Best!\n",
            "Epoch  4/20 | Train Loss: 0.2496 | Val Loss: 0.4107  Best!\n",
            "Epoch  5/20 | Train Loss: 0.2031 | Val Loss: 0.3946  Best!\n",
            "Epoch  6/20 | Train Loss: 0.1747 | Val Loss: 0.4039\n",
            "Epoch  7/20 | Train Loss: 0.1346 | Val Loss: 0.4216\n",
            "Epoch  8/20 | Train Loss: 0.1170 | Val Loss: 0.4469\n",
            "Epoch  9/20 | Train Loss: 0.1039 | Val Loss: 0.4404\n",
            "Epoch 10/20 | Train Loss: 0.0777 | Val Loss: 0.4052\n",
            "Epoch 11/20 | Train Loss: 0.0679 | Val Loss: 0.5182\n",
            "Epoch 12/20 | Train Loss: 0.0685 | Val Loss: 0.4444\n",
            "Epoch 13/20 | Train Loss: 0.0607 | Val Loss: 0.5565\n",
            "Epoch 14/20 | Train Loss: 0.0557 | Val Loss: 0.4665\n",
            "Epoch 15/20 | Train Loss: 0.0440 | Val Loss: 0.4968\n",
            "Epoch 16/20 | Train Loss: 0.0467 | Val Loss: 0.4827\n",
            "Epoch 17/20 | Train Loss: 0.0424 | Val Loss: 0.4905\n",
            "Epoch 18/20 | Train Loss: 0.0409 | Val Loss: 0.4763\n",
            "Epoch 19/20 | Train Loss: 0.0327 | Val Loss: 0.5525\n",
            "Epoch 20/20 | Train Loss: 0.0360 | Val Loss: 0.5041\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.3946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 - Full Fine-tuning\n",
        "# ========================\n",
        "\n",
        "print(\"\\nüìä EVALUANDO RESNET18 - FULL FINE-TUNING\")\n",
        "\n",
        "resnet_full_results = evaluate_model(\n",
        "    resnet_full_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - Full Fine-tuning - Offsite Test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUXfA6cIfym0",
        "outputId": "b71e2b26-1298-4808-e995-34e01af9af96"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä EVALUANDO RESNET18 - FULL FINE-TUNING\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - Full Fine-tuning - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8828\n",
            "  Recall:    0.9143\n",
            "  F-score:   0.8982\n",
            "\n",
            "G:\n",
            "  Precision: 0.8750\n",
            "  Recall:    0.7143\n",
            "  F-score:   0.7865\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.7368\n",
            "  Recall:    0.6364\n",
            "  F-score:   0.6829\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.7892\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 1.3 - EfficientNet - Full Fine-tuning\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 1.3 - EFFICIENTNET - FULL FINE-TUNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "effnet_full = build_model(\"efficientnet\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "effnet_full.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_efficientnet_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. DESCONGELAR TODO\n",
        "for param in effnet_full.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Verificar\n",
        "trainable_params = sum(p.numel() for p in effnet_full.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in effnet_full.parameters())\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
        "\n",
        "# 3. Configurar entrenamiento con LR BAJO\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(effnet_full.parameters(), lr=1e-4)  # ‚Üê LR m√°s bajo\n",
        "\n",
        "# 4. Entrenar\n",
        "effnet_full_trained, train_losses_eff_full, val_losses_eff_full = train_model(\n",
        "    model=effnet_full,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"EfficientNet - Full Fine-tuning\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1lI5jYQf2Jj",
        "outputId": "2e0aabf2-346c-488e-c923-34c5653b3e78"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 1.3 - EFFICIENTNET - FULL FINE-TUNING\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo pre-entrenado cargado\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      4,011,391\n",
            "   Trainable:  4,011,391 (100.00%)\n",
            "\n",
            " Iniciando entrenamiento de EfficientNet - Full Fine-tuning\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 0.9968 | Val Loss: 0.7834  Best!\n",
            "Epoch  2/20 | Train Loss: 0.4794 | Val Loss: 0.6220  Best!\n",
            "Epoch  3/20 | Train Loss: 0.3731 | Val Loss: 0.5435  Best!\n",
            "Epoch  4/20 | Train Loss: 0.2751 | Val Loss: 0.5004  Best!\n",
            "Epoch  5/20 | Train Loss: 0.2414 | Val Loss: 0.5002  Best!\n",
            "Epoch  6/20 | Train Loss: 0.2182 | Val Loss: 0.4929  Best!\n",
            "Epoch  7/20 | Train Loss: 0.1981 | Val Loss: 0.4792  Best!\n",
            "Epoch  8/20 | Train Loss: 0.1613 | Val Loss: 0.5240\n",
            "Epoch  9/20 | Train Loss: 0.1614 | Val Loss: 0.5086\n",
            "Epoch 10/20 | Train Loss: 0.1356 | Val Loss: 0.5179\n",
            "Epoch 11/20 | Train Loss: 0.1181 | Val Loss: 0.5111\n",
            "Epoch 12/20 | Train Loss: 0.1120 | Val Loss: 0.5328\n",
            "Epoch 13/20 | Train Loss: 0.1028 | Val Loss: 0.5164\n",
            "Epoch 14/20 | Train Loss: 0.0955 | Val Loss: 0.5583\n",
            "Epoch 15/20 | Train Loss: 0.0784 | Val Loss: 0.5310\n",
            "Epoch 16/20 | Train Loss: 0.0698 | Val Loss: 0.5171\n",
            "Epoch 17/20 | Train Loss: 0.0692 | Val Loss: 0.5530\n",
            "Epoch 18/20 | Train Loss: 0.0653 | Val Loss: 0.5744\n",
            "Epoch 19/20 | Train Loss: 0.0581 | Val Loss: 0.5174\n",
            "Epoch 20/20 | Train Loss: 0.0430 | Val Loss: 0.5382\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.4792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar EfficientNet - Full Fine-tuning\n",
        "# ========================\n",
        "\n",
        "print(\"\\nüìä EVALUANDO EFFICIENTNET - FULL FINE-TUNING\")\n",
        "\n",
        "effnet_full_results = evaluate_model(\n",
        "    effnet_full_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"EfficientNet - Full Fine-tuning - Offsite Test\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVeFRjxUgs95",
        "outputId": "7d8c6b27-3160-4f77-a082-44816d57571c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä EVALUANDO EFFICIENTNET - FULL FINE-TUNING\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - EfficientNet - Full Fine-tuning - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8519\n",
            "  Recall:    0.8214\n",
            "  F-score:   0.8364\n",
            "\n",
            "G:\n",
            "  Precision: 0.7273\n",
            "  Recall:    0.6531\n",
            "  F-score:   0.6882\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.4688\n",
            "  Recall:    0.6818\n",
            "  F-score:   0.5556\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.6934\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# COMPARACI√ìN COMPLETA: TASK 1.1, 1.2, 1.3\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä RESUMEN COMPLETO - TASK 1: TRANSFER LEARNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Tabla de resultados\n",
        "print(f\"\\n{'Modelo':<15} {'Task 1.1':<12} {'Task 1.2':<12} {'Task 1.3':<12} {'Mejor':<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# ResNet18\n",
        "resnet_scores = [\n",
        "    task1_1_results['resnet18']['average_f1'] * 100,\n",
        "    resnet_frozen_results['average_f1'] * 100,\n",
        "    resnet_full_results['average_f1'] * 100\n",
        "]\n",
        "best_resnet = max(resnet_scores)\n",
        "print(f\"{'ResNet18':<15} {resnet_scores[0]:>6.2f}%     {resnet_scores[1]:>6.2f}%     \"\n",
        "      f\"{resnet_scores[2]:>6.2f}%     {best_resnet:>6.2f}%\")\n",
        "\n",
        "# EfficientNet\n",
        "effnet_scores = [\n",
        "    task1_1_results['efficientnet']['average_f1'] * 100,\n",
        "    effnet_frozen_results['average_f1'] * 100,\n",
        "    effnet_full_results['average_f1'] * 100\n",
        "]\n",
        "best_effnet = max(effnet_scores)\n",
        "print(f\"{'EfficientNet':<15} {effnet_scores[0]:>6.2f}%     {effnet_scores[1]:>6.2f}%     \"\n",
        "      f\"{effnet_scores[2]:>6.2f}%     {best_effnet:>6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\"üéØ REFERENCIAS (onsite test):\")\n",
        "print(f\"{'Modelo':<15} {'Task 1.1':<12} {'Task 1.2':<12} {'Task 1.3':<12}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'ResNet18':<15} {'56.7%':<12} {'61.4%':<12} {'78.8%':<12}\")\n",
        "print(f\"{'EfficientNet':<15} {'60.4%':<12} {'73.5%':<12} {'80.4%':<12}\")\n",
        "\n",
        "print(\"\\nüí° Nota: Estos son resultados en offsite test.\")\n",
        "print(\"   Los resultados onsite se obtendr√°n al submitir a Kaggle.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Guardar mejores modelos\n",
        "task1_best_models = {\n",
        "    'resnet18': resnet_full_trained if resnet_scores[2] == best_resnet else\n",
        "                (resnet_frozen_trained if resnet_scores[1] == best_resnet else resnet_model),\n",
        "    'efficientnet': effnet_full_trained if effnet_scores[2] == best_effnet else\n",
        "                    (effnet_frozen_trained if effnet_scores[1] == best_effnet else effnet_model)\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Mejores modelos guardados en memoria para predicciones onsite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNLEz0a0gzAG",
        "outputId": "c1972855-adb3-49c8-c189-47b98000a451"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä RESUMEN COMPLETO - TASK 1: TRANSFER LEARNING\n",
            "================================================================================\n",
            "\n",
            "Modelo          Task 1.1     Task 1.2     Task 1.3     Mejor     \n",
            "----------------------------------------------------------------------\n",
            "ResNet18         51.26%      45.31%      78.92%      78.92%\n",
            "EfficientNet     55.41%      70.74%      69.34%      70.74%\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "üéØ REFERENCIAS (onsite test):\n",
            "Modelo          Task 1.1     Task 1.2     Task 1.3    \n",
            "----------------------------------------------------------------------\n",
            "ResNet18        56.7%        61.4%        78.8%       \n",
            "EfficientNet    60.4%        73.5%        80.4%       \n",
            "\n",
            "üí° Nota: Estos son resultados en offsite test.\n",
            "   Los resultados onsite se obtendr√°n al submitir a Kaggle.\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Mejores modelos guardados en memoria para predicciones onsite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# GUARDAR MODELOS ENTRENADOS\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üíæ GUARDANDO MODELOS ENTRENADOS\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "import os\n",
        "\n",
        "# Crear directorio para modelos\n",
        "os.makedirs('./trained_models', exist_ok=True)\n",
        "\n",
        "# Guardar todos los modelos de Task 1\n",
        "models_to_save = {\n",
        "    # Task 1.1 (ya los ten√≠amos pre-entrenados, no los guardamos de nuevo)\n",
        "\n",
        "    # Task 1.2\n",
        "    'resnet18_task1_2_frozen.pt': resnet_frozen_trained,\n",
        "    'efficientnet_task1_2_frozen.pt': effnet_frozen_trained,\n",
        "\n",
        "    # Task 1.3\n",
        "    'resnet18_task1_3_full.pt': resnet_full_trained,\n",
        "    'efficientnet_task1_3_full.pt': effnet_full_trained,\n",
        "}\n",
        "\n",
        "for filename, model in models_to_save.items():\n",
        "    filepath = f'./trained_models/{filename}'\n",
        "    torch.save(model.state_dict(), filepath)\n",
        "    print(f\"‚úÖ Guardado: {filename}\")\n",
        "\n",
        "print(f\"\\nüíæ Total: {len(models_to_save)} modelos guardados en ./trained_models/\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvr3fnDxinU1",
        "outputId": "d63780ca-ebc8-4019-d85f-c64656fde256"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üíæ GUARDANDO MODELOS ENTRENADOS\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Guardado: resnet18_task1_2_frozen.pt\n",
            "‚úÖ Guardado: efficientnet_task1_2_frozen.pt\n",
            "‚úÖ Guardado: resnet18_task1_3_full.pt\n",
            "‚úÖ Guardado: efficientnet_task1_3_full.pt\n",
            "\n",
            "üíæ Total: 4 modelos guardados en ./trained_models/\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# GENERAR PREDICCIONES ONSITE TEST\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üì§ GENERANDO PREDICCIONES PARA ONSITE TEST (KAGGLE)\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Configurar paths\n",
        "onsite_test_csv = f\"{BASE_DIR}/onsite_test_submission.csv\"\n",
        "onsite_test_dir = f\"{BASE_DIR}/images/onsite_test\"\n",
        "\n",
        "# Cargar template\n",
        "submission_template = pd.read_csv(onsite_test_csv)\n",
        "print(f\"üìã Template cargado: {len(submission_template)} im√°genes\")\n",
        "print(f\"Columnas: {list(submission_template.columns)}\")\n",
        "print(f\"\\nPrimeras filas del template:\")\n",
        "print(submission_template.head())\n",
        "\n",
        "# Crear dataset para onsite (SIN labels)\n",
        "class OnsiteTestDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_name = row['id']\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, img_name\n",
        "\n",
        "# Transform (sin augmentation para test)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Crear dataset y loader\n",
        "onsite_ds = OnsiteTestDataset(onsite_test_csv, onsite_test_dir, test_transform)\n",
        "onsite_loader = DataLoader(onsite_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Onsite dataset cargado: {len(onsite_ds)} im√°genes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY4wWHeLliT8",
        "outputId": "f5229bc7-c161-4e67-f17a-23a37a8437f7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üì§ GENERANDO PREDICCIONES PARA ONSITE TEST (KAGGLE)\n",
            "================================================================================\n",
            "\n",
            "üìã Template cargado: 250 im√°genes\n",
            "Columnas: ['id', 'D', 'G', 'A']\n",
            "\n",
            "Primeras filas del template:\n",
            "               id  D  G  A\n",
            "0  4595_right.jpg  0  0  0\n",
            "1   4155_left.jpg  0  0  0\n",
            "2    597_left.jpg  0  0  0\n",
            "3  4268_right.jpg  0  0  0\n",
            "4   579_right.jpg  0  0  0\n",
            "\n",
            "‚úÖ Onsite dataset cargado: 250 im√°genes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Funci√≥n para generar CSV de predicciones\n",
        "# ============================================\n",
        "\n",
        "def generate_predictions(model, dataloader, device, output_filename):\n",
        "    \"\"\"\n",
        "    Genera predicciones y guarda CSV para Kaggle.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    image_names = []\n",
        "\n",
        "    print(f\"\\nüîÆ Generando predicciones con {output_filename}...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            image_names.extend(names)\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df = pd.DataFrame(predictions, columns=['D', 'G', 'A'])\n",
        "    df.insert(0, 'id', image_names)\n",
        "\n",
        "    # Guardar CSV\n",
        "    output_path = f'./results/{output_filename}'\n",
        "    os.makedirs('./results', exist_ok=True)\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Predicciones guardadas en: {output_path}\")\n",
        "    print(f\"   Total predicciones: {len(df)}\")\n",
        "    print(f\"\\nüìä Distribuci√≥n de predicciones:\")\n",
        "    print(f\"   DR (D):  {df['D'].sum()} positivos\")\n",
        "    print(f\"   G:       {df['G'].sum()} positivos\")\n",
        "    print(f\"   AMD (A): {df['A'].sum()} positivos\")\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\" Funci√≥n de predicciones definida!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWnGwT-slokz",
        "outputId": "faa37e34-7915-4411-9bf7-28190d5cf501"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Funci√≥n de predicciones definida!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# GENERAR PREDICCIONES PARA TODOS LOS MODELOS\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ GENERANDO TODAS LAS PREDICCIONES ONSITE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Diccionario de modelos a evaluar\n",
        "models_for_prediction = {\n",
        "    # Task 1.1\n",
        "    'task1_1_resnet18.csv': resnet_model,\n",
        "    'task1_1_efficientnet.csv': effnet_model,\n",
        "\n",
        "    # Task 1.2\n",
        "    'task1_2_resnet18.csv': resnet_frozen_trained,\n",
        "    'task1_2_efficientnet.csv': effnet_frozen_trained,\n",
        "\n",
        "    # Task 1.3\n",
        "    'task1_3_resnet18.csv': resnet_full_trained,\n",
        "    'task1_3_efficientnet.csv': effnet_full_trained,\n",
        "}\n",
        "\n",
        "# Generar predicciones\n",
        "predictions_summary = {}\n",
        "\n",
        "for filename, model in models_for_prediction.items():\n",
        "    df = generate_predictions(model, onsite_loader, DEVICE, filename)\n",
        "    predictions_summary[filename] = df\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ TODAS LAS PREDICCIONES GENERADAS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìÅ Archivos creados en ./results/:\")\n",
        "for filename in models_for_prediction.keys():\n",
        "    print(f\"   ‚úÖ {filename}\")\n",
        "\n",
        "print(\"\\nüí° Pr√≥ximo paso: Subir estos CSVs a Kaggle para obtener los scores reales\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh9lWA1ultxL",
        "outputId": "c56befaf-1d78-4fb4-8ad8-97bbd91e8d9a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ GENERANDO TODAS LAS PREDICCIONES ONSITE\n",
            "================================================================================\n",
            "\n",
            "üîÆ Generando predicciones con task1_1_resnet18.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task1_1_resnet18.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  124 positivos\n",
            "   G:       35 positivos\n",
            "   AMD (A): 56 positivos\n",
            "\n",
            "üîÆ Generando predicciones con task1_1_efficientnet.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task1_1_efficientnet.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  149 positivos\n",
            "   G:       57 positivos\n",
            "   AMD (A): 72 positivos\n",
            "\n",
            "üîÆ Generando predicciones con task1_2_resnet18.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task1_2_resnet18.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  221 positivos\n",
            "   G:       8 positivos\n",
            "   AMD (A): 2 positivos\n",
            "\n",
            "üîÆ Generando predicciones con task1_2_efficientnet.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task1_2_efficientnet.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  182 positivos\n",
            "   G:       32 positivos\n",
            "   AMD (A): 22 positivos\n",
            "\n",
            "üîÆ Generando predicciones con task1_3_resnet18.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task1_3_resnet18.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  178 positivos\n",
            "   G:       47 positivos\n",
            "   AMD (A): 30 positivos\n",
            "\n",
            "üîÆ Generando predicciones con task1_3_efficientnet.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task1_3_efficientnet.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  180 positivos\n",
            "   G:       45 positivos\n",
            "   AMD (A): 36 positivos\n",
            "\n",
            "================================================================================\n",
            "‚úÖ TODAS LAS PREDICCIONES GENERADAS\n",
            "================================================================================\n",
            "\n",
            "üìÅ Archivos creados en ./results/:\n",
            "   ‚úÖ task1_1_resnet18.csv\n",
            "   ‚úÖ task1_1_efficientnet.csv\n",
            "   ‚úÖ task1_2_resnet18.csv\n",
            "   ‚úÖ task1_2_efficientnet.csv\n",
            "   ‚úÖ task1_3_resnet18.csv\n",
            "   ‚úÖ task1_3_efficientnet.csv\n",
            "\n",
            "üí° Pr√≥ximo paso: Subir estos CSVs a Kaggle para obtener los scores reales\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DESCARGAR CSVs PARA KAGGLE\n",
        "# ============================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì• DESCARGANDO ARCHIVOS CSV PARA KAGGLE SUBMISSION\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Solo descargamos los mejores modelos (Task 1.3) + Task 1.1 y 1.2 para completar\n",
        "csvs_to_download = [\n",
        "    # Task 1.1 (baseline)\n",
        "    './results/task1_1_resnet18.csv',\n",
        "    './results/task1_1_efficientnet.csv',\n",
        "\n",
        "    # Task 1.2 (frozen backbone)\n",
        "    './results/task1_2_resnet18.csv',\n",
        "    './results/task1_2_efficientnet.csv',\n",
        "\n",
        "    # Task 1.3 (full fine-tuning) - LOS MEJORES\n",
        "    './results/task1_3_resnet18.csv',\n",
        "    './results/task1_3_efficientnet.csv',\n",
        "]\n",
        "\n",
        "for csv_path in csvs_to_download:\n",
        "    print(f\"‚¨áÔ∏è  Descargando: {csv_path}\")\n",
        "    files.download(csv_path)\n",
        "\n",
        "print(\"\\n‚úÖ Archivos descargados a tu computadora!\")\n",
        "print(\"üí° Busca los archivos en tu carpeta de Descargas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "IVAu_DDjult7",
        "outputId": "db034b47-c63f-4499-c4db-eda7887cbdf3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• DESCARGANDO ARCHIVOS CSV PARA KAGGLE SUBMISSION\n",
            "======================================================================\n",
            "\n",
            "‚¨áÔ∏è  Descargando: ./results/task1_1_resnet18.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f5fd68ac-910f-4384-abc6-8745c6de5c72\", \"task1_1_resnet18.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è  Descargando: ./results/task1_1_efficientnet.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c1be11db-2552-40d9-8cf7-5b0e1746d370\", \"task1_1_efficientnet.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è  Descargando: ./results/task1_2_resnet18.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7566e2d7-6cd7-4720-beb9-289e9d6a1ea5\", \"task1_2_resnet18.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è  Descargando: ./results/task1_2_efficientnet.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3567796f-4ae3-402b-a627-effcda13b81f\", \"task1_2_efficientnet.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è  Descargando: ./results/task1_3_resnet18.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_14a5a238-3015-43f3-bd5c-0c4241d916d5\", \"task1_3_resnet18.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨áÔ∏è  Descargando: ./results/task1_3_efficientnet.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f4cb5ef-7621-49a4-a9ab-650ed706f844\", \"task1_3_efficientnet.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Archivos descargados a tu computadora!\n",
            "üí° Busca los archivos en tu carpeta de Descargas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2"
      ],
      "metadata": {
        "id": "wZIj65Bc3o5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 2: LOSS FUNCTIONS\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" INICIANDO TASK 2: LOSS FUNCTIONS\")\n",
        "print(\"   Objetivo: Abordar el desbalanceo de clases\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Verificar distribuci√≥n de clases\n",
        "train_df = pd.read_csv(f\"{BASE_DIR}/train.csv\")\n",
        "\n",
        "class_counts = train_df[['D', 'G', 'A']].sum()\n",
        "print(\" DISTRIBUCI√ìN DE CLASES EN TRAINING SET:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"DR (D):   {class_counts['D']:3d} casos ({100*class_counts['D']/len(train_df):.1f}%)\")\n",
        "print(f\"G:        {class_counts['G']:3d} casos ({100*class_counts['G']/len(train_df):.1f}%)\")\n",
        "print(f\"AMD (A):  {class_counts['A']:3d} casos ({100*class_counts['A']/len(train_df):.1f}%)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n  Problema: DR tiene {class_counts['D']/class_counts['A']:.1f}x m√°s casos que AMD\")\n",
        "print(\"   El modelo puede ignorar las clases minoritarias\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK0iRwIu3oi0",
        "outputId": "aaa0abac-7331-4113-9bda-1996397c655a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " INICIANDO TASK 2: LOSS FUNCTIONS\n",
            "   Objetivo: Abordar el desbalanceo de clases\n",
            "================================================================================\n",
            "\n",
            " DISTRIBUCI√ìN DE CLASES EN TRAINING SET:\n",
            "============================================================\n",
            "DR (D):   517 casos (64.6%)\n",
            "G:        163 casos (20.4%)\n",
            "AMD (A):  142 casos (17.8%)\n",
            "============================================================\n",
            "\n",
            "  Problema: DR tiene 3.6x m√°s casos que AMD\n",
            "   El modelo puede ignorar las clases minoritarias\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 2.1: FOCAL LOSS\n",
        "# ============================================\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss para multi-label classification.\n",
        "\n",
        "    FL(pt) = -Œ± * (1 - pt)^Œ≥ * log(pt)\n",
        "\n",
        "    Args:\n",
        "        alpha: Peso para balancear clases (default: 0.25)\n",
        "        gamma: Factor de enfoque en ejemplos dif√≠ciles (default: 2.0)\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Calcular probabilidades\n",
        "        BCE_loss = nn.functional.binary_cross_entropy_with_logits(\n",
        "            inputs, targets, reduction='none'\n",
        "        )\n",
        "\n",
        "        # Calcular pt (probabilidad del target)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "\n",
        "        # Aplicar focal loss\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "\n",
        "        return focal_loss.mean()\n",
        "\n",
        "print(\" Focal Loss implementado!\")\n",
        "print(f\"   Alpha: 0.25\")\n",
        "print(f\"   Gamma: 2.0\")\n",
        "print(f\"\\n Focal Loss penaliza m√°s los ejemplos dif√≠ciles de clasificar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8-4A7pC365q",
        "outputId": "ecbad473-9d1b-48ea-c147-d305487fe890"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Focal Loss implementado!\n",
            "   Alpha: 0.25\n",
            "   Gamma: 2.0\n",
            "\n",
            " Focal Loss penaliza m√°s los ejemplos dif√≠ciles de clasificar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 2.2: CLASS-BALANCED LOSS\n",
        "# ============================================\n",
        "\n",
        "class ClassBalancedLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Class-Balanced Loss para multi-label classification.\n",
        "    Re-pondera BCE Loss seg√∫n la frecuencia de cada clase.\n",
        "\n",
        "    Args:\n",
        "        class_counts: Tensor con el n√∫mero de samples positivos por clase\n",
        "    \"\"\"\n",
        "    def __init__(self, class_counts):\n",
        "        super(ClassBalancedLoss, self).__init__()\n",
        "\n",
        "        # Calcular pesos inversamente proporcionales a frecuencia\n",
        "        total_samples = class_counts.sum()\n",
        "        self.weights = total_samples / (len(class_counts) * class_counts)\n",
        "\n",
        "        # Normalizar pesos\n",
        "        self.weights = self.weights / self.weights.sum() * len(class_counts)\n",
        "\n",
        "        print(f\" Pesos calculados para Class-Balanced Loss:\")\n",
        "        disease_names = ['DR', 'G', 'AMD']\n",
        "        for i, name in enumerate(disease_names):\n",
        "            print(f\"   {name}: {self.weights[i]:.4f} (freq: {class_counts[i]})\")\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # BCE loss sin reducci√≥n\n",
        "        BCE_loss = nn.functional.binary_cross_entropy_with_logits(\n",
        "            inputs, targets, reduction='none'\n",
        "        )\n",
        "\n",
        "        # Aplicar pesos por clase\n",
        "        weights = self.weights.to(inputs.device)\n",
        "        weighted_loss = BCE_loss * weights\n",
        "\n",
        "        return weighted_loss.mean()\n",
        "\n",
        "# Calcular class counts del training set\n",
        "class_counts = torch.tensor([\n",
        "    train_df['D'].sum(),\n",
        "    train_df['G'].sum(),\n",
        "    train_df['A'].sum()\n",
        "], dtype=torch.float32)\n",
        "\n",
        "print(\"\\n Class-Balanced Loss implementado!\")\n",
        "print(f\" Las clases minoritarias (G, AMD) tendr√°n m√°s peso en el loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_zwZGJ14Ajr",
        "outputId": "3c536d6a-710d-4b65-e995-8040696736d6"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Class-Balanced Loss implementado!\n",
            " Las clases minoritarias (G, AMD) tendr√°n m√°s peso en el loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Seleccionar modelo base para Task 2\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" SELECCI√ìN DE MODELO PARA TASK 2\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nResultados Task 1.3 (onsite):\")\n",
        "print(f\"  ResNet18:     82.29% \")\n",
        "print(f\"  EfficientNet: 80.24%\")\n",
        "\n",
        "print(\"\\n Decisi√≥n: Usaremos ResNet18 para Task 2\")\n",
        "print(\"   (Mejor performance en Task 1.3)\")\n",
        "\n",
        "SELECTED_MODEL = \"resnet18\"\n",
        "print(f\"\\n Modelo seleccionado: {SELECTED_MODEL}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Dp6htU4SYf",
        "outputId": "dcd6ba88-0ceb-4fc2-f03c-f390306c5ad4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " SELECCI√ìN DE MODELO PARA TASK 2\n",
            "================================================================================\n",
            "\n",
            "Resultados Task 1.3 (onsite):\n",
            "  ResNet18:     82.29% \n",
            "  EfficientNet: 80.24%\n",
            "\n",
            " Decisi√≥n: Usaremos ResNet18 para Task 2\n",
            "   (Mejor performance en Task 1.3)\n",
            "\n",
            " Modelo seleccionado: resnet18\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 2.1 - Entrenar ResNet18 con Focal Loss\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" TASK 2.1 - RESNET18 CON FOCAL LOSS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "resnet_focal = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_focal.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\" Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. Descongelar todo (full fine-tuning)\n",
        "for param in resnet_focal.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\" Todas las capas desbloqueadas (full fine-tuning)\")\n",
        "\n",
        "# 3. Configurar entrenamiento con FOCAL LOSS\n",
        "criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "optimizer = optim.Adam(resnet_focal.parameters(), lr=1e-4)\n",
        "\n",
        "print(f\"\\n Loss Function: Focal Loss (alpha=0.25, gamma=2.0)\")\n",
        "print(f\" Optimizer: Adam (lr=1e-4)\")\n",
        "\n",
        "# 4. Entrenar\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "resnet_focal_trained, train_losses_focal, val_losses_focal = train_model(\n",
        "    model=resnet_focal,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 - Focal Loss\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D79Qmf1n82Ff",
        "outputId": "33ec9365-e503-4d37-cd4d-a84bcb8a9aa5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " TASK 2.1 - RESNET18 CON FOCAL LOSS\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modelo pre-entrenado cargado\n",
            " Todas las capas desbloqueadas (full fine-tuning)\n",
            "\n",
            " Loss Function: Focal Loss (alpha=0.25, gamma=2.0)\n",
            " Optimizer: Adam (lr=1e-4)\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 - Focal Loss\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 0.1566 | Val Loss: 0.1100  Best!\n",
            "Epoch  2/20 | Train Loss: 0.0459 | Val Loss: 0.0502  Best!\n",
            "Epoch  3/20 | Train Loss: 0.0333 | Val Loss: 0.0423  Best!\n",
            "Epoch  4/20 | Train Loss: 0.0220 | Val Loss: 0.0390  Best!\n",
            "Epoch  5/20 | Train Loss: 0.0184 | Val Loss: 0.0377  Best!\n",
            "Epoch  6/20 | Train Loss: 0.0171 | Val Loss: 0.0359  Best!\n",
            "Epoch  7/20 | Train Loss: 0.0148 | Val Loss: 0.0368\n",
            "Epoch  8/20 | Train Loss: 0.0126 | Val Loss: 0.0345  Best!\n",
            "Epoch  9/20 | Train Loss: 0.0115 | Val Loss: 0.0328  Best!\n",
            "Epoch 10/20 | Train Loss: 0.0090 | Val Loss: 0.0379\n",
            "Epoch 11/20 | Train Loss: 0.0089 | Val Loss: 0.0412\n",
            "Epoch 12/20 | Train Loss: 0.0073 | Val Loss: 0.0412\n",
            "Epoch 13/20 | Train Loss: 0.0060 | Val Loss: 0.0371\n",
            "Epoch 14/20 | Train Loss: 0.0056 | Val Loss: 0.0377\n",
            "Epoch 15/20 | Train Loss: 0.0049 | Val Loss: 0.0390\n",
            "Epoch 16/20 | Train Loss: 0.0036 | Val Loss: 0.0431\n",
            "Epoch 17/20 | Train Loss: 0.0029 | Val Loss: 0.0429\n",
            "Epoch 18/20 | Train Loss: 0.0022 | Val Loss: 0.0477\n",
            "Epoch 19/20 | Train Loss: 0.0027 | Val Loss: 0.0604\n",
            "Epoch 20/20 | Train Loss: 0.0028 | Val Loss: 0.0531\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.0328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 con Focal Loss\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO RESNET18 CON FOCAL LOSS\")\n",
        "\n",
        "resnet_focal_results = evaluate_model(\n",
        "    resnet_focal_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - Focal Loss - Offsite Test\"\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "torch.save(resnet_focal_trained.state_dict(),\n",
        "           './trained_models/resnet18_task2_1_focal.pt')\n",
        "print(\"\\n Modelo guardado: resnet18_task2_1_focal.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rtqU0039USx",
        "outputId": "304303f0-30af-4d5f-f152-e97f8ebd935d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO RESNET18 CON FOCAL LOSS\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - Focal Loss - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8857\n",
            "  Recall:    0.8857\n",
            "  F-score:   0.8857\n",
            "\n",
            "G:\n",
            "  Precision: 0.8421\n",
            "  Recall:    0.6531\n",
            "  F-score:   0.7356\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.5667\n",
            "  Recall:    0.7727\n",
            "  F-score:   0.6538\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.7584\n",
            "======================================================================\n",
            "\n",
            "\n",
            " Modelo guardado: resnet18_task2_1_focal.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 2.2 - Entrenar ResNet18 con Class-Balanced Loss\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" TASK 2.2 - RESNET18 CON CLASS-BALANCED LOSS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Cargar modelo pre-entrenado\n",
        "resnet_balanced = build_model(\"resnet18\", num_classes=3, pretrained=False).to(DEVICE)\n",
        "resnet_balanced.load_state_dict(torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        "))\n",
        "\n",
        "print(\" Modelo pre-entrenado cargado\")\n",
        "\n",
        "# 2. Descongelar todo\n",
        "for param in resnet_balanced.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\" Todas las capas desbloqueadas (full fine-tuning)\")\n",
        "\n",
        "# 3. Configurar entrenamiento con CLASS-BALANCED LOSS\n",
        "criterion = ClassBalancedLoss(class_counts)  # ‚Üê AQU√ç VER√ÅS LOS PESOS\n",
        "optimizer = optim.Adam(resnet_balanced.parameters(), lr=1e-4)\n",
        "\n",
        "print(f\"\\n Loss Function: Class-Balanced Loss\")\n",
        "print(f\" Optimizer: Adam (lr=1e-4)\")\n",
        "\n",
        "# 4. Entrenar\n",
        "resnet_balanced_trained, train_losses_balanced, val_losses_balanced = train_model(\n",
        "    model=resnet_balanced,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 - Class-Balanced Loss\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i1Y_TM49pU6",
        "outputId": "6f6db494-ce4a-4c52-9937-cee1ce8814df"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " TASK 2.2 - RESNET18 CON CLASS-BALANCED LOSS\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modelo pre-entrenado cargado\n",
            " Todas las capas desbloqueadas (full fine-tuning)\n",
            " Pesos calculados para Class-Balanced Loss:\n",
            "   DR: 0.3840 (freq: 517.0)\n",
            "   G: 1.2179 (freq: 163.0)\n",
            "   AMD: 1.3981 (freq: 142.0)\n",
            "\n",
            " Loss Function: Class-Balanced Loss\n",
            " Optimizer: Adam (lr=1e-4)\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 - Class-Balanced Loss\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 0.6428 | Val Loss: 0.5775  Best!\n",
            "Epoch  2/20 | Train Loss: 0.3310 | Val Loss: 0.4393  Best!\n",
            "Epoch  3/20 | Train Loss: 0.2484 | Val Loss: 0.4066  Best!\n",
            "Epoch  4/20 | Train Loss: 0.2008 | Val Loss: 0.4067\n",
            "Epoch  5/20 | Train Loss: 0.1671 | Val Loss: 0.3771  Best!\n",
            "Epoch  6/20 | Train Loss: 0.1471 | Val Loss: 0.3806\n",
            "Epoch  7/20 | Train Loss: 0.1048 | Val Loss: 0.3933\n",
            "Epoch  8/20 | Train Loss: 0.0955 | Val Loss: 0.4451\n",
            "Epoch  9/20 | Train Loss: 0.0744 | Val Loss: 0.4011\n",
            "Epoch 10/20 | Train Loss: 0.0622 | Val Loss: 0.4104\n",
            "Epoch 11/20 | Train Loss: 0.0512 | Val Loss: 0.4194\n",
            "Epoch 12/20 | Train Loss: 0.0543 | Val Loss: 0.4222\n",
            "Epoch 13/20 | Train Loss: 0.0304 | Val Loss: 0.4374\n",
            "Epoch 14/20 | Train Loss: 0.0400 | Val Loss: 0.4786\n",
            "Epoch 15/20 | Train Loss: 0.0304 | Val Loss: 0.4938\n",
            "Epoch 16/20 | Train Loss: 0.0379 | Val Loss: 0.5094\n",
            "Epoch 17/20 | Train Loss: 0.0326 | Val Loss: 0.4148\n",
            "Epoch 18/20 | Train Loss: 0.0251 | Val Loss: 0.4272\n",
            "Epoch 19/20 | Train Loss: 0.0239 | Val Loss: 0.4670\n",
            "Epoch 20/20 | Train Loss: 0.0271 | Val Loss: 0.4920\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.3771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 con Class-Balanced Loss\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO RESNET18 CON CLASS-BALANCED LOSS\")\n",
        "\n",
        "resnet_balanced_results = evaluate_model(\n",
        "    resnet_balanced_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 - Class-Balanced Loss - Offsite Test\"\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "torch.save(resnet_balanced_trained.state_dict(),\n",
        "           './trained_models/resnet18_task2_2_balanced.pt')\n",
        "print(\"\\n Modelo guardado: resnet18_task2_2_balanced.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l5tjtDv-PIP",
        "outputId": "34b4c7b4-1f0c-4ca2-977f-6c193638ac5d"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO RESNET18 CON CLASS-BALANCED LOSS\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 - Class-Balanced Loss - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8323\n",
            "  Recall:    0.9571\n",
            "  F-score:   0.8904\n",
            "\n",
            "G:\n",
            "  Precision: 0.9032\n",
            "  Recall:    0.5714\n",
            "  F-score:   0.7000\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.7619\n",
            "  Recall:    0.7273\n",
            "  F-score:   0.7442\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.7782\n",
            "======================================================================\n",
            "\n",
            "\n",
            " Modelo guardado: resnet18_task2_2_balanced.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# COMPARACI√ìN COMPLETA: TASK 1 vs TASK 2\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä COMPARACI√ìN: TASK 1.3 vs TASK 2 (ResNet18)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Resultados\n",
        "comparison = {\n",
        "    'Task 1.3 (BCE Loss)': resnet_full_results['average_f1'] * 100,\n",
        "    'Task 2.1 (Focal Loss)': resnet_focal_results['average_f1'] * 100,\n",
        "    'Task 2.2 (Class-Balanced)': resnet_balanced_results['average_f1'] * 100,\n",
        "}\n",
        "\n",
        "baseline = comparison['Task 1.3 (BCE Loss)']\n",
        "\n",
        "print(f\"\\n{'Loss Function':<25} {'F-score':<12} {'vs Baseline':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, score in comparison.items():\n",
        "    diff = score - baseline\n",
        "    status = \"‚úÖ\" if diff >= 0 else \"‚ö†Ô∏è\"\n",
        "    print(f\"{name:<25} {score:>6.2f}%     {diff:>+6.2f}%  {status}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"üéØ REFERENCIAS Task 2 (onsite test):\")\n",
        "print(\"   Baseline (Task 1.3): 78.8%\")\n",
        "print(\"   Comparable:          ~78.8% (70% de puntos)\")\n",
        "print(\"   +0.5% mejor:         >79.3% (85% de puntos)\")\n",
        "print(\"   +1.0% mejor:         >79.8% (100% de puntos)\")\n",
        "\n",
        "# Determinar mejor modelo\n",
        "best_task2_name = max(comparison.items(), key=lambda x: x[1])\n",
        "print(f\"\\n‚≠ê MEJOR MODELO TASK 2: {best_task2_name[0]} ({best_task2_name[1]:.2f}%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Guardar el mejor para predicciones onsite\n",
        "if comparison['Task 2.1 (Focal Loss)'] >= comparison['Task 2.2 (Class-Balanced)']:\n",
        "    best_task2_model = resnet_focal_trained\n",
        "    best_task2_name = \"focal\"\n",
        "else:\n",
        "    best_task2_model = resnet_balanced_trained\n",
        "    best_task2_name = \"balanced\"\n",
        "\n",
        "print(f\"\\n‚úÖ Mejor modelo de Task 2 guardado en memoria para predicciones onsite\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AniV7tBb-ZMZ",
        "outputId": "bb1e2425-e06b-4df0-c089-bbee4dac9038"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä COMPARACI√ìN: TASK 1.3 vs TASK 2 (ResNet18)\n",
            "================================================================================\n",
            "\n",
            "Loss Function             F-score      vs Baseline    \n",
            "------------------------------------------------------------\n",
            "Task 1.3 (BCE Loss)        78.92%      +0.00%  ‚úÖ\n",
            "Task 2.1 (Focal Loss)      75.84%      -3.08%  ‚ö†Ô∏è\n",
            "Task 2.2 (Class-Balanced)  77.82%      -1.10%  ‚ö†Ô∏è\n",
            "\n",
            "------------------------------------------------------------\n",
            "üéØ REFERENCIAS Task 2 (onsite test):\n",
            "   Baseline (Task 1.3): 78.8%\n",
            "   Comparable:          ~78.8% (70% de puntos)\n",
            "   +0.5% mejor:         >79.3% (85% de puntos)\n",
            "   +1.0% mejor:         >79.8% (100% de puntos)\n",
            "\n",
            "‚≠ê MEJOR MODELO TASK 2: Task 1.3 (BCE Loss) (78.92%)\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Mejor modelo de Task 2 guardado en memoria para predicciones onsite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# GENERAR PREDICCIONES TASK 2 PARA KAGGLE\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üì§ GENERANDO PREDICCIONES TASK 2 PARA ONSITE TEST\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Ya tenemos el dataset onsite y la funci√≥n generate_predictions\n",
        "\n",
        "# 1. Predicci√≥n con Focal Loss (gamma=2.0)\n",
        "print(\"üîÆ Generando predicciones: Focal Loss (gamma=2.0)...\")\n",
        "pred_focal = generate_predictions(\n",
        "    resnet_focal_trained,\n",
        "    onsite_loader,\n",
        "    DEVICE,\n",
        "    \"task2_1_focal_loss.csv\"\n",
        ")\n",
        "\n",
        "# 2. Predicci√≥n con Class-Balanced Loss\n",
        "print(\"\\nüîÆ Generando predicciones: Class-Balanced Loss...\")\n",
        "pred_balanced = generate_predictions(\n",
        "    resnet_balanced_trained,\n",
        "    onsite_loader,\n",
        "    DEVICE,\n",
        "    \"task2_2_class_balanced.csv\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ PREDICCIONES TASK 2 GENERADAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä RESUMEN:\")\n",
        "print(f\"   Focal Loss (offsite):       75.84%\")\n",
        "print(f\"   Class-Balanced (offsite):   77.82% ‚≠ê MEJOR\")\n",
        "print(f\"\\nüìÅ Archivos listos para Kaggle:\")\n",
        "print(\"   ‚úÖ task2_1_focal_loss.csv\")\n",
        "print(\"   ‚úÖ task2_2_class_balanced.csv\")\n",
        "\n",
        "print(\"\\nüí° RECOMENDACI√ìN:\")\n",
        "print(\"   Submitir AMBOS a Kaggle para Task 2:\")\n",
        "print(\"   1. Class-Balanced (esperado: ~77-78%)\")\n",
        "print(\"   2. Focal Loss (esperado: ~75-76%)\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhGBTPs3QV5m",
        "outputId": "d1012bc0-bcb2-4932-d1b7-e9a131cec92b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üì§ GENERANDO PREDICCIONES TASK 2 PARA ONSITE TEST\n",
            "================================================================================\n",
            "\n",
            "üîÆ Generando predicciones: Focal Loss (gamma=2.0)...\n",
            "\n",
            "üîÆ Generando predicciones con task2_1_focal_loss.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task2_1_focal_loss.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  180 positivos\n",
            "   G:       43 positivos\n",
            "   AMD (A): 37 positivos\n",
            "\n",
            "üîÆ Generando predicciones: Class-Balanced Loss...\n",
            "\n",
            "üîÆ Generando predicciones con task2_2_class_balanced.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task2_2_class_balanced.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  204 positivos\n",
            "   G:       35 positivos\n",
            "   AMD (A): 22 positivos\n",
            "\n",
            "================================================================================\n",
            "‚úÖ PREDICCIONES TASK 2 GENERADAS\n",
            "================================================================================\n",
            "\n",
            "üìä RESUMEN:\n",
            "   Focal Loss (offsite):       75.84%\n",
            "   Class-Balanced (offsite):   77.82% ‚≠ê MEJOR\n",
            "\n",
            "üìÅ Archivos listos para Kaggle:\n",
            "   ‚úÖ task2_1_focal_loss.csv\n",
            "   ‚úÖ task2_2_class_balanced.csv\n",
            "\n",
            "üí° RECOMENDACI√ìN:\n",
            "   Submitir AMBOS a Kaggle para Task 2:\n",
            "   1. Class-Balanced (esperado: ~77-78%)\n",
            "   2. Focal Loss (esperado: ~75-76%)\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DESCARGAR CSVs TASK 2\n",
        "# ============================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\" DESCARGANDO ARCHIVOS CSV - TASK 2\\n\")\n",
        "\n",
        "csvs_task2 = [\n",
        "    './results/task2_1_focal_loss.csv',\n",
        "    './results/task2_2_class_balanced.csv',\n",
        "]\n",
        "\n",
        "for csv_path in csvs_task2:\n",
        "    print(f\"‚¨á  Descargando: {csv_path}\")\n",
        "    files.download(csv_path)\n",
        "\n",
        "print(\"\\n Archivos descargados!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "MBonVyMLQdPj",
        "outputId": "f772247e-7974-429f-a823-6ff5b1df2104"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DESCARGANDO ARCHIVOS CSV - TASK 2\n",
            "\n",
            "‚¨á  Descargando: ./results/task2_1_focal_loss.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cecdac7f-609b-483b-94f5-24fb573fa18e\", \"task2_1_focal_loss.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨á  Descargando: ./results/task2_2_class_balanced.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_783d85b9-7dfc-452f-bd9a-1ef00b9baf1f\", \"task2_2_class_balanced.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Archivos descargados!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# RESULTADOS FINALES TASK 2 - ACTUALIZADOS\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä RESULTADOS FINALES TASK 2\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "task2_final_results = {\n",
        "    'Focal Loss': {\n",
        "        'offsite': 75.84,\n",
        "        'onsite': 79.23  # ‚Üê Actualizado con Kaggle\n",
        "    },\n",
        "    'Class-Balanced': {\n",
        "        'offsite': 77.82,\n",
        "        'onsite': 79.59  # ‚Üê Actualizado con Kaggle\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\nüìà COMPARACI√ìN OFFSITE vs ONSITE:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Loss Function':<20} {'Offsite':<12} {'Onsite':<12} {'Diferencia':<12}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for loss_name, scores in task2_final_results.items():\n",
        "    diff = scores['onsite'] - scores['offsite']\n",
        "    print(f\"{loss_name:<20} {scores['offsite']:>6.2f}%     {scores['onsite']:>6.2f}%     \"\n",
        "          f\"{diff:>+6.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ COMPARACI√ìN CON REFERENCIAS (ONSITE):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "baseline = 78.8\n",
        "print(f\"{'Loss Function':<20} {'Score':<12} {'vs Baseline':<15} {'Status'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for loss_name, scores in task2_final_results.items():\n",
        "    onsite = scores['onsite']\n",
        "    diff = onsite - baseline\n",
        "\n",
        "    if diff >= 1.0:\n",
        "        status = \"üéâ 100% pts\"\n",
        "    elif diff >= 0.5:\n",
        "        status = \"‚≠ê 85% pts\"\n",
        "    elif diff >= 0:\n",
        "        status = \"‚úÖ 70% pts\"\n",
        "    else:\n",
        "        status = \"‚ö†Ô∏è 50% pts\"\n",
        "\n",
        "    print(f\"{loss_name:<20} {onsite:>6.2f}%     {diff:>+6.2f}%       {status}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚≠ê MEJOR MODELO: Class-Balanced Loss (79.59%)\")\n",
        "print(f\"   Mejora sobre baseline: +0.79%\")\n",
        "print(f\"   Puntos estimados Task 2: ~8/10 puntos\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n‚úÖ TASK 2 COMPLETADO!\")\n",
        "print(\"üöÄ Listo para continuar con Task 3 (Attention Mechanisms - 15 puntos)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tDtic2PSeDl",
        "outputId": "2b70699d-8f61-410d-a0e4-30dc3968d74f"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä RESULTADOS FINALES TASK 2\n",
            "================================================================================\n",
            "\n",
            "üìà COMPARACI√ìN OFFSITE vs ONSITE:\n",
            "--------------------------------------------------------------------------------\n",
            "Loss Function        Offsite      Onsite       Diferencia  \n",
            "--------------------------------------------------------------------------------\n",
            "Focal Loss            75.84%      79.23%      +3.39%\n",
            "Class-Balanced        77.82%      79.59%      +1.77%\n",
            "\n",
            "================================================================================\n",
            "üéØ COMPARACI√ìN CON REFERENCIAS (ONSITE):\n",
            "--------------------------------------------------------------------------------\n",
            "Loss Function        Score        vs Baseline     Status\n",
            "--------------------------------------------------------------------------------\n",
            "Focal Loss            79.23%      +0.43%       ‚úÖ 70% pts\n",
            "Class-Balanced        79.59%      +0.79%       ‚≠ê 85% pts\n",
            "\n",
            "================================================================================\n",
            "‚≠ê MEJOR MODELO: Class-Balanced Loss (79.59%)\n",
            "   Mejora sobre baseline: +0.79%\n",
            "   Puntos estimados Task 2: ~8/10 puntos\n",
            "================================================================================\n",
            "\n",
            "‚úÖ TASK 2 COMPLETADO!\n",
            "üöÄ Listo para continuar con Task 3 (Attention Mechanisms - 15 puntos)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 3"
      ],
      "metadata": {
        "id": "UQeAJc5GTpYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ============================================\n",
        "# TASK 3: ATTENTION MECHANISMS\n",
        "# ============================================\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" INICIANDO TASK 3: ATTENTION MECHANISMS\")\n",
        "print(\"   Objetivo: Mejorar el modelo con mecanismos de atenci√≥n\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(\" Sub-tareas:\")\n",
        "print(\"   Task 3.1: Squeeze-and-Excitation (SE) - 6 puntos\")\n",
        "print(\"   Task 3.2: Multi-head Attention (MHA) - 9 puntos\")\n",
        "print(\"\\n Baseline: Task 1.3 ResNet18 - 82.29% (onsite)\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7r_dCgJTo4w",
        "outputId": "d2c1cf40-0525-4679-fce6-ce23647c97da"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " INICIANDO TASK 3: ATTENTION MECHANISMS\n",
            "   Objetivo: Mejorar el modelo con mecanismos de atenci√≥n\n",
            "================================================================================\n",
            "\n",
            " Sub-tareas:\n",
            "   Task 3.1: Squeeze-and-Excitation (SE) - 6 puntos\n",
            "   Task 3.2: Multi-head Attention (MHA) - 9 puntos\n",
            "\n",
            " Baseline: Task 1.3 ResNet18 - 82.29% (onsite)\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 3.1: SQUEEZE-AND-EXCITATION (SE) MODULE\n",
        "# ============================================\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Squeeze-and-Excitation Block\n",
        "\n",
        "    Paper: \"Squeeze-and-Excitation Networks\" (Hu et al., 2018)\n",
        "\n",
        "    Proceso:\n",
        "    1. Squeeze: Global Average Pooling ‚Üí vector de tama√±o [C]\n",
        "    2. Excitation: FC ‚Üí ReLU ‚Üí FC ‚Üí Sigmoid ‚Üí pesos por canal\n",
        "    3. Scale: Multiplica features por pesos aprendidos\n",
        "\n",
        "    Args:\n",
        "        channels: N√∫mero de canales de entrada\n",
        "        reduction: Factor de reducci√≥n para la capa FC (default: 16)\n",
        "    \"\"\"\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "\n",
        "        # Squeeze: Global Average Pooling (adaptativo)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Excitation: 2 capas FC\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, channels, height, width]\n",
        "        batch, channels, _, _ = x.size()\n",
        "\n",
        "        # Squeeze: [batch, channels, H, W] ‚Üí [batch, channels, 1, 1]\n",
        "        y = self.avg_pool(x)\n",
        "\n",
        "        # [batch, channels, 1, 1] ‚Üí [batch, channels]\n",
        "        y = y.view(batch, channels)\n",
        "\n",
        "        # Excitation: [batch, channels] ‚Üí [batch, channels]\n",
        "        y = self.fc(y)\n",
        "\n",
        "        # [batch, channels] ‚Üí [batch, channels, 1, 1]\n",
        "        y = y.view(batch, channels, 1, 1)\n",
        "\n",
        "        # Scale: multiplicar features originales por pesos\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "print(\" SEBlock implementado!\")\n",
        "print(\"\\n Arquitectura:\")\n",
        "print(\"   Input: [B, C, H, W]\")\n",
        "print(\"   ‚Üí Global Avg Pool: [B, C, 1, 1]\")\n",
        "print(\"   ‚Üí FC(C, C//16) ‚Üí ReLU ‚Üí FC(C//16, C) ‚Üí Sigmoid\")\n",
        "print(\"   ‚Üí Multiply: [B, C, H, W] * [B, C, 1, 1]\")\n",
        "print(\"   Output: [B, C, H, W] (con atenci√≥n por canal)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2iHtKD1T27Q",
        "outputId": "cb99f5fd-b01e-4722-b8fe-5c13b7533169"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SEBlock implementado!\n",
            "\n",
            " Arquitectura:\n",
            "   Input: [B, C, H, W]\n",
            "   ‚Üí Global Avg Pool: [B, C, 1, 1]\n",
            "   ‚Üí FC(C, C//16) ‚Üí ReLU ‚Üí FC(C//16, C) ‚Üí Sigmoid\n",
            "   ‚Üí Multiply: [B, C, H, W] * [B, C, 1, 1]\n",
            "   Output: [B, C, H, W] (con atenci√≥n por canal)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Construir ResNet18 + SE Blocks\n",
        "# ============================================\n",
        "\n",
        "class ResNet18_SE(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet18 con Squeeze-and-Excitation blocks a√±adidos.\n",
        "\n",
        "    SE blocks se agregan despu√©s de cada bloque residual.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=3, reduction=16):\n",
        "        super(ResNet18_SE, self).__init__()\n",
        "\n",
        "        # Cargar ResNet18 pre-entrenado\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        # Copiar capas iniciales (conv1, bn1, relu, maxpool)\n",
        "        self.conv1 = resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "\n",
        "        # Layer 1: [64 channels]\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.se1 = SEBlock(64, reduction)\n",
        "\n",
        "        # Layer 2: [128 channels]\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.se2 = SEBlock(128, reduction)\n",
        "\n",
        "        # Layer 3: [256 channels]\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.se3 = SEBlock(256, reduction)\n",
        "\n",
        "        # Layer 4: [512 channels]\n",
        "        self.layer4 = resnet.layer4\n",
        "        self.se4 = SEBlock(512, reduction)\n",
        "\n",
        "        # Global Average Pooling + Classifier\n",
        "        self.avgpool = resnet.avgpool\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Residual blocks + SE\n",
        "        x = self.layer1(x)\n",
        "        x = self.se1(x)  # ‚Üê SE after layer 1\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.se2(x)  # ‚Üê SE after layer 2\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.se3(x)  # ‚Üê SE after layer 3\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = self.se4(x)  # ‚Üê SE after layer 4\n",
        "\n",
        "        # Classifier\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\" ResNet18_SE implementado!\")\n",
        "print(\"\\n  Arquitectura:\")\n",
        "print(\"   ResNet18 base\")\n",
        "print(\"   + SE Block despu√©s de layer1 (64 channels)\")\n",
        "print(\"   + SE Block despu√©s de layer2 (128 channels)\")\n",
        "print(\"   + SE Block despu√©s de layer3 (256 channels)\")\n",
        "print(\"   + SE Block despu√©s de layer4 (512 channels)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS8Nrr5sUAHg",
        "outputId": "1030315f-0efb-4e57-f1a7-e7b4468f2ff2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ResNet18_SE implementado!\n",
            "\n",
            "  Arquitectura:\n",
            "   ResNet18 base\n",
            "   + SE Block despu√©s de layer1 (64 channels)\n",
            "   + SE Block despu√©s de layer2 (128 channels)\n",
            "   + SE Block despu√©s de layer3 (256 channels)\n",
            "   + SE Block despu√©s de layer4 (512 channels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 3.1 - Entrenar ResNet18 + SE\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 3.1 - RESNET18 + SQUEEZE-AND-EXCITATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Crear modelo\n",
        "resnet_se = ResNet18_SE(num_classes=3, reduction=16).to(DEVICE)\n",
        "\n",
        "print(\"\\nüèóÔ∏è  Modelo creado: ResNet18 + SE Blocks\")\n",
        "\n",
        "# 2. Cargar pesos pre-entrenados del backbone\n",
        "# (solo las capas compatibles)\n",
        "pretrained_dict = torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        ")\n",
        "\n",
        "# Filtrar solo las capas que existen en ambos modelos\n",
        "model_dict = resnet_se.state_dict()\n",
        "pretrained_dict_filtered = {\n",
        "    k: v for k, v in pretrained_dict.items()\n",
        "    if k in model_dict and model_dict[k].shape == v.shape\n",
        "}\n",
        "\n",
        "# Cargar pesos compatibles\n",
        "model_dict.update(pretrained_dict_filtered)\n",
        "resnet_se.load_state_dict(model_dict)\n",
        "\n",
        "print(f\"‚úÖ Cargados {len(pretrained_dict_filtered)}/{len(pretrained_dict)} pesos pre-entrenados\")\n",
        "print(\"üí° SE blocks inicializados aleatoriamente (nuevos)\")\n",
        "\n",
        "# 3. Verificar par√°metros\n",
        "total_params = sum(p.numel() for p in resnet_se.parameters())\n",
        "trainable_params = sum(p.numel() for p in resnet_se.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nüìä Par√°metros del modelo:\")\n",
        "print(f\"   Total:      {total_params:,}\")\n",
        "print(f\"   Trainable:  {trainable_params:,}\")\n",
        "\n",
        "# 4. Configurar entrenamiento\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(resnet_se.parameters(), lr=1e-4)\n",
        "\n",
        "print(f\"\\nüéØ Loss: BCE with Logits\")\n",
        "print(f\"üéØ Optimizer: Adam (lr=1e-4)\")\n",
        "\n",
        "# 5. Entrenar\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "resnet_se_trained, train_losses_se, val_losses_se = train_model(\n",
        "    model=resnet_se,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 + SE\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acvAo7fCUI_A",
        "outputId": "4e6831fc-2382-4d2c-fd0d-91e06f5ddf8a"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 3.1 - RESNET18 + SQUEEZE-AND-EXCITATION\n",
            "================================================================================\n",
            "\n",
            "üèóÔ∏è  Modelo creado: ResNet18 + SE Blocks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cargados 122/122 pesos pre-entrenados\n",
            "üí° SE blocks inicializados aleatoriamente (nuevos)\n",
            "\n",
            "üìä Par√°metros del modelo:\n",
            "   Total:      11,221,571\n",
            "   Trainable:  11,221,571\n",
            "\n",
            "üéØ Loss: BCE with Logits\n",
            "üéØ Optimizer: Adam (lr=1e-4)\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 + SE\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 0.5467 | Val Loss: 0.4627  Best!\n",
            "Epoch  2/20 | Train Loss: 0.3360 | Val Loss: 0.4218  Best!\n",
            "Epoch  3/20 | Train Loss: 0.2732 | Val Loss: 0.3934  Best!\n",
            "Epoch  4/20 | Train Loss: 0.2285 | Val Loss: 0.4001\n",
            "Epoch  5/20 | Train Loss: 0.1887 | Val Loss: 0.4149\n",
            "Epoch  6/20 | Train Loss: 0.1462 | Val Loss: 0.4290\n",
            "Epoch  7/20 | Train Loss: 0.1322 | Val Loss: 0.4159\n",
            "Epoch  8/20 | Train Loss: 0.1024 | Val Loss: 0.3960\n",
            "Epoch  9/20 | Train Loss: 0.0985 | Val Loss: 0.4590\n",
            "Epoch 10/20 | Train Loss: 0.0815 | Val Loss: 0.4237\n",
            "Epoch 11/20 | Train Loss: 0.0665 | Val Loss: 0.4447\n",
            "Epoch 12/20 | Train Loss: 0.0586 | Val Loss: 0.4064\n",
            "Epoch 13/20 | Train Loss: 0.0428 | Val Loss: 0.4098\n",
            "Epoch 14/20 | Train Loss: 0.0399 | Val Loss: 0.4720\n",
            "Epoch 15/20 | Train Loss: 0.0361 | Val Loss: 0.5438\n",
            "Epoch 16/20 | Train Loss: 0.0339 | Val Loss: 0.4432\n",
            "Epoch 17/20 | Train Loss: 0.0304 | Val Loss: 0.4599\n",
            "Epoch 18/20 | Train Loss: 0.0253 | Val Loss: 0.5187\n",
            "Epoch 19/20 | Train Loss: 0.0221 | Val Loss: 0.5159\n",
            "Epoch 20/20 | Train Loss: 0.0173 | Val Loss: 0.5042\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.3934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 + SE\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO RESNET18 + SE\")\n",
        "\n",
        "resnet_se_results = evaluate_model(\n",
        "    resnet_se_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 + SE - Offsite Test\"\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "torch.save(resnet_se_trained.state_dict(),\n",
        "           './trained_models/resnet18_task3_1_se.pt')\n",
        "print(\"\\n Modelo guardado: resnet18_task3_1_se.pt\")\n",
        "\n",
        "# Comparar con baseline\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" COMPARACI√ìN CON BASELINE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "baseline = resnet_full_results['average_f1'] * 100\n",
        "se_score = resnet_se_results['average_f1'] * 100\n",
        "\n",
        "print(f\"\\nTask 1.3 (ResNet18):    {baseline:.2f}%\")\n",
        "print(f\"Task 3.1 (ResNet18+SE): {se_score:.2f}%\")\n",
        "print(f\"Diferencia:             {se_score - baseline:+.2f}%\")\n",
        "\n",
        "if se_score > baseline:\n",
        "    print(\"\\n ¬°SE BLOCKS MEJORARON EL MODELO!\")\n",
        "else:\n",
        "    print(\"\\n  SE Blocks no mejoraron, pero es un resultado v√°lido\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJe0WhvmUsHN",
        "outputId": "62ef9474-83a8-4ffe-c110-e54c926054ab"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO RESNET18 + SE\n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 + SE - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8808\n",
            "  Recall:    0.9500\n",
            "  F-score:   0.9141\n",
            "\n",
            "G:\n",
            "  Precision: 0.8611\n",
            "  Recall:    0.6327\n",
            "  F-score:   0.7294\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.7647\n",
            "  Recall:    0.5909\n",
            "  F-score:   0.6667\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.7701\n",
            "======================================================================\n",
            "\n",
            "\n",
            " Modelo guardado: resnet18_task3_1_se.pt\n",
            "\n",
            "================================================================================\n",
            " COMPARACI√ìN CON BASELINE\n",
            "================================================================================\n",
            "\n",
            "Task 1.3 (ResNet18):    78.92%\n",
            "Task 3.1 (ResNet18+SE): 77.01%\n",
            "Diferencia:             -1.92%\n",
            "\n",
            "  SE Blocks no mejoraron, pero es un resultado v√°lido\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 3.2: MULTI-HEAD ATTENTION (MHA) MODULE\n",
        "# ============================================\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head Self-Attention para features convolucionales.\n",
        "\n",
        "    Paper: \"Attention is All You Need\" (Vaswani et al., 2017)\n",
        "\n",
        "    Adaptado para CNNs: convierte [B, C, H, W] a secuencias.\n",
        "\n",
        "    Args:\n",
        "        embed_dim: Dimensi√≥n de embedding (n√∫mero de canales)\n",
        "        num_heads: N√∫mero de cabezas de atenci√≥n\n",
        "        dropout: Dropout rate (default: 0.1)\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads=8, dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        assert embed_dim % num_heads == 0, \"embed_dim debe ser divisible por num_heads\"\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        # Proyecciones lineales para Q, K, V\n",
        "        self.qkv = nn.Linear(embed_dim, embed_dim * 3, bias=False)\n",
        "\n",
        "        # Proyecci√≥n de salida\n",
        "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, channels, height, width]\n",
        "        B, C, H, W = x.shape\n",
        "        N = H * W  # N√∫mero de tokens (pixeles)\n",
        "\n",
        "        # Reshape: [B, C, H, W] ‚Üí [B, N, C]\n",
        "        x = x.flatten(2).transpose(1, 2)  # [B, H*W, C]\n",
        "\n",
        "        # Proyectar a Q, K, V\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)  # [3, B, num_heads, N, head_dim]\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # Attention: Q @ K^T / sqrt(d)\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale  # [B, num_heads, N, N]\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        # Aplicar atenci√≥n a V\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)  # [B, N, C]\n",
        "\n",
        "        # Proyecci√≥n de salida\n",
        "        x = self.proj(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Reshape back: [B, N, C] ‚Üí [B, C, H, W]\n",
        "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\" MultiHeadAttention implementado!\")\n",
        "print(\"\\n Arquitectura:\")\n",
        "print(\"   Input: [B, C, H, W]\")\n",
        "print(\"   ‚Üí Flatten: [B, H*W, C]\")\n",
        "print(\"   ‚Üí Linear(C, 3*C): Q, K, V projections\")\n",
        "print(\"   ‚Üí Multi-head Attention: [B, num_heads, H*W, H*W]\")\n",
        "print(\"   ‚Üí Linear(C, C): Output projection\")\n",
        "print(\"   ‚Üí Reshape: [B, C, H, W]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz2ZTG4fW-WS",
        "outputId": "29e7611d-ee08-408e-c2ca-1239f53ca9da"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MultiHeadAttention implementado!\n",
            "\n",
            " Arquitectura:\n",
            "   Input: [B, C, H, W]\n",
            "   ‚Üí Flatten: [B, H*W, C]\n",
            "   ‚Üí Linear(C, 3*C): Q, K, V projections\n",
            "   ‚Üí Multi-head Attention: [B, num_heads, H*W, H*W]\n",
            "   ‚Üí Linear(C, C): Output projection\n",
            "   ‚Üí Reshape: [B, C, H, W]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Construir ResNet18 + MHA (OPTIMIZADO)\n",
        "# ============================================\n",
        "\n",
        "class ResNet18_MHA_Optimized(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet18 con Multi-Head Attention SOLO en layers finales.\n",
        "\n",
        "    Esto reduce uso de memoria significativamente.\n",
        "    MHA se aplica donde las features son m√°s abstractas y menos pixeles.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=3, num_heads=8):\n",
        "        super(ResNet18_MHA_Optimized, self).__init__()\n",
        "\n",
        "        # Cargar ResNet18 pre-entrenado\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        # Copiar capas iniciales\n",
        "        self.conv1 = resnet.conv1\n",
        "        self.bn1 = resnet.bn1\n",
        "        self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "\n",
        "        # Layer 1: [64 channels] - SIN MHA (demasiados tokens)\n",
        "        self.layer1 = resnet.layer1\n",
        "\n",
        "        # Layer 2: [128 channels] - SIN MHA (muchos tokens)\n",
        "        self.layer2 = resnet.layer2\n",
        "\n",
        "        # Layer 3: [256 channels] - CON MHA\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.mha3 = MultiHeadAttention(256, num_heads=num_heads)\n",
        "\n",
        "        # Layer 4: [512 channels] - CON MHA\n",
        "        self.layer4 = resnet.layer4\n",
        "        self.mha4 = MultiHeadAttention(512, num_heads=num_heads)\n",
        "\n",
        "        # Global Average Pooling + Classifier\n",
        "        self.avgpool = resnet.avgpool\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Layer 1 y 2: SIN MHA\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "\n",
        "        # Layer 3: CON MHA\n",
        "        x = self.layer3(x)\n",
        "        x = x + self.mha3(x)  # ‚Üê MHA aqu√≠ (16√ó16 tokens)\n",
        "\n",
        "        # Layer 4: CON MHA\n",
        "        x = self.layer4(x)\n",
        "        x = x + self.mha4(x)  # ‚Üê MHA aqu√≠ (8√ó8 tokens)\n",
        "\n",
        "        # Classifier\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\" ResNet18_MHA_Optimized implementado!\")\n",
        "print(\"\\n  Arquitectura:\")\n",
        "print(\"   ResNet18 base\")\n",
        "print(\"   + layer1 (64 channels) - SIN MHA\")\n",
        "print(\"   + layer2 (128 channels) - SIN MHA\")\n",
        "print(\"   + layer3 (256 channels) - CON MHA  (16√ó16 = 256 tokens)\")\n",
        "print(\"   + layer4 (512 channels) - CON MHA  (8√ó8 = 64 tokens)\")\n",
        "print(\"\\n Esto reduce DR√ÅSTICAMENTE el uso de memoria\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXAN6KQDXFQf",
        "outputId": "44512c5c-004f-483b-d1e7-8d4792a62e52"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ResNet18_MHA_Optimized implementado!\n",
            "\n",
            "  Arquitectura:\n",
            "   ResNet18 base\n",
            "   + layer1 (64 channels) - SIN MHA\n",
            "   + layer2 (128 channels) - SIN MHA\n",
            "   + layer3 (256 channels) - CON MHA  (16√ó16 = 256 tokens)\n",
            "   + layer4 (512 channels) - CON MHA  (8√ó8 = 64 tokens)\n",
            "\n",
            " Esto reduce DR√ÅSTICAMENTE el uso de memoria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TASK 3.2 - Entrenar ResNet18 + MHA (OPTIMIZADO)\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üî¨ TASK 3.2 - RESNET18 + MULTI-HEAD ATTENTION (OPTIMIZADO)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Crear modelo OPTIMIZADO\n",
        "resnet_mha_opt = ResNet18_MHA_Optimized(num_classes=3, num_heads=8).to(DEVICE)\n",
        "\n",
        "print(\"\\nüèóÔ∏è  Modelo creado: ResNet18 + MHA (solo en layer3 y layer4)\")\n",
        "\n",
        "# 2. Cargar pesos pre-entrenados\n",
        "pretrained_dict = torch.load(\n",
        "    f\"{BASE_DIR}/pretrained_backbone/ckpt_resnet18_ep50.pt\",\n",
        "    map_location=DEVICE\n",
        ")\n",
        "\n",
        "model_dict = resnet_mha_opt.state_dict()\n",
        "pretrained_dict_filtered = {\n",
        "    k: v for k, v in pretrained_dict.items()\n",
        "    if k in model_dict and model_dict[k].shape == v.shape\n",
        "}\n",
        "\n",
        "model_dict.update(pretrained_dict_filtered)\n",
        "resnet_mha_opt.load_state_dict(model_dict)\n",
        "\n",
        "print(f\"‚úÖ Cargados {len(pretrained_dict_filtered)}/{len(pretrained_dict)} pesos pre-entrenados\")\n",
        "\n",
        "# 3. Par√°metros\n",
        "total_params = sum(p.numel() for p in resnet_mha_opt.parameters())\n",
        "print(f\"\\nüìä Par√°metros: {total_params:,}\")\n",
        "\n",
        "# 4. CREAR DATALOADERS CON BATCH SIZE REDUCIDO\n",
        "print(\"\\n‚öôÔ∏è  Creando dataloaders con batch_size=16 (reducido de 32)\")\n",
        "\n",
        "train_loader_small = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader_small = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "# 5. Configurar entrenamiento\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(resnet_mha_opt.parameters(), lr=1e-4)\n",
        "\n",
        "print(f\"üéØ Loss: BCE with Logits\")\n",
        "print(f\"üéØ Optimizer: Adam (lr=1e-4)\")\n",
        "print(f\"üéØ Batch size: 16 (para ahorrar memoria)\")\n",
        "\n",
        "# 6. Entrenar\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "resnet_mha_trained, train_losses_mha, val_losses_mha = train_model(\n",
        "    model=resnet_mha_opt,\n",
        "    train_loader=train_loader_small,\n",
        "    val_loader=val_loader_small,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=DEVICE,\n",
        "    model_name=\"ResNet18 + MHA (Optimized)\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ryTORfSXWpT",
        "outputId": "0db2d6f2-e86c-4bb9-c46b-ef1a798c1ffc"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üî¨ TASK 3.2 - RESNET18 + MULTI-HEAD ATTENTION (OPTIMIZADO)\n",
            "================================================================================\n",
            "\n",
            "üèóÔ∏è  Modelo creado: ResNet18 + MHA (solo en layer3 y layer4)\n",
            "‚úÖ Cargados 122/122 pesos pre-entrenados\n",
            "\n",
            "üìä Par√°metros: 12,489,539\n",
            "\n",
            "‚öôÔ∏è  Creando dataloaders con batch_size=16 (reducido de 32)\n",
            "üéØ Loss: BCE with Logits\n",
            "üéØ Optimizer: Adam (lr=1e-4)\n",
            "üéØ Batch size: 16 (para ahorrar memoria)\n",
            "\n",
            " Iniciando entrenamiento de ResNet18 + MHA (Optimized)\n",
            "   √âpocas: 20\n",
            "   Device: cuda\n",
            "----------------------------------------------------------------------\n",
            "Epoch  1/20 | Train Loss: 0.6033 | Val Loss: 0.5013  Best!\n",
            "Epoch  2/20 | Train Loss: 0.3284 | Val Loss: 0.3911  Best!\n",
            "Epoch  3/20 | Train Loss: 0.2586 | Val Loss: 0.4032\n",
            "Epoch  4/20 | Train Loss: 0.2195 | Val Loss: 0.4478\n",
            "Epoch  5/20 | Train Loss: 0.1854 | Val Loss: 0.4225\n",
            "Epoch  6/20 | Train Loss: 0.1622 | Val Loss: 0.4931\n",
            "Epoch  7/20 | Train Loss: 0.1356 | Val Loss: 0.4340\n",
            "Epoch  8/20 | Train Loss: 0.1241 | Val Loss: 0.4924\n",
            "Epoch  9/20 | Train Loss: 0.1145 | Val Loss: 0.4461\n",
            "Epoch 10/20 | Train Loss: 0.0707 | Val Loss: 0.5169\n",
            "Epoch 11/20 | Train Loss: 0.0877 | Val Loss: 0.4927\n",
            "Epoch 12/20 | Train Loss: 0.0758 | Val Loss: 0.5282\n",
            "Epoch 13/20 | Train Loss: 0.0653 | Val Loss: 0.5417\n",
            "Epoch 14/20 | Train Loss: 0.0555 | Val Loss: 0.4805\n",
            "Epoch 15/20 | Train Loss: 0.0648 | Val Loss: 0.7456\n",
            "Epoch 16/20 | Train Loss: 0.0620 | Val Loss: 0.5141\n",
            "Epoch 17/20 | Train Loss: 0.0465 | Val Loss: 0.5388\n",
            "Epoch 18/20 | Train Loss: 0.0330 | Val Loss: 0.5577\n",
            "Epoch 19/20 | Train Loss: 0.0551 | Val Loss: 0.7370\n",
            "Epoch 20/20 | Train Loss: 0.0330 | Val Loss: 0.7901\n",
            "----------------------------------------------------------------------\n",
            " Entrenamiento completado!\n",
            "   Best Val Loss: 0.3911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Evaluar ResNet18 + MHA\n",
        "# ========================\n",
        "\n",
        "print(\"\\n EVALUANDO RESNET18 + MHA \")\n",
        "\n",
        "resnet_mha_results = evaluate_model(\n",
        "    resnet_mha_trained,\n",
        "    offsite_test_loader,\n",
        "    DEVICE,\n",
        "    \"ResNet18 + MHA (Optimized) - Offsite Test\"\n",
        ")\n",
        "\n",
        "# Guardar modelo\n",
        "torch.save(resnet_mha_trained.state_dict(),\n",
        "           './trained_models/resnet18_task3_2_mha.pt')\n",
        "print(\"\\n Modelo guardado: resnet18_task3_2_mha.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwsCpYVYZihB",
        "outputId": "08a480ae-598d-4b06-b7a7-a3d59ff5124a"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EVALUANDO RESNET18 + MHA \n",
            "\n",
            "======================================================================\n",
            " RESULTADOS - ResNet18 + MHA (Optimized) - Offsite Test\n",
            "======================================================================\n",
            "\n",
            "DR:\n",
            "  Precision: 0.8553\n",
            "  Recall:    0.9714\n",
            "  F-score:   0.9097\n",
            "\n",
            "G:\n",
            "  Precision: 0.9394\n",
            "  Recall:    0.6327\n",
            "  F-score:   0.7561\n",
            "\n",
            "AMD:\n",
            "  Precision: 0.8333\n",
            "  Recall:    0.6818\n",
            "  F-score:   0.7500\n",
            "\n",
            "======================================================================\n",
            " AVERAGE F-SCORE: 0.8053\n",
            "======================================================================\n",
            "\n",
            "\n",
            " Modelo guardado: resnet18_task3_2_mha.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# COMPARACI√ìN COMPLETA TASK 3\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" RESUMEN TASK 3: ATTENTION MECHANISMS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "task3_results = {\n",
        "    'Task 1.3 (Baseline)': resnet_full_results['average_f1'] * 100,\n",
        "    'Task 3.1 (SE)': resnet_se_results['average_f1'] * 100,\n",
        "    'Task 3.2 (MHA)': resnet_mha_results['average_f1'] * 100,\n",
        "}\n",
        "\n",
        "baseline = task3_results['Task 1.3 (Baseline)']\n",
        "\n",
        "print(f\"\\n{'Modelo':<25} {'F-score':<12} {'vs Baseline':<15} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "best_task3_model = None\n",
        "best_task3_score = 0\n",
        "best_task3_name = \"\"\n",
        "best_task3_key = \"\"\n",
        "\n",
        "for name, score in task3_results.items():\n",
        "    diff = score - baseline\n",
        "\n",
        "    # Guardar el mejor de Task 3\n",
        "    if 'Task 3' in name and score > best_task3_score:\n",
        "        best_task3_score = score\n",
        "        best_task3_name = name\n",
        "        if 'SE' in name:\n",
        "            best_task3_key = 'SE'\n",
        "            best_task3_model = resnet_se_trained\n",
        "        else:\n",
        "            best_task3_key = 'MHA'\n",
        "            best_task3_model = resnet_mha_trained\n",
        "\n",
        "    # Determinar status\n",
        "    if diff >= 1.5:\n",
        "        status = \"üéâ 100% pts\"\n",
        "    elif diff >= 1.0:\n",
        "        status = \"‚≠ê 85% pts\"\n",
        "    elif diff >= 0:\n",
        "        status = \"‚úÖ 70% pts\"\n",
        "    elif diff >= -2:\n",
        "        status = \"‚ö†Ô∏è 60% pts\"\n",
        "    else:\n",
        "        status = \"‚ùå 50% pts\"\n",
        "\n",
        "    print(f\"{name:<25} {score:>6.2f}%     {diff:>+6.2f}%       {status}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "print(\" REFERENCIAS Task 3 (onsite test):\")\n",
        "print(\"   Baseline (Task 1.3): 78.8%\")\n",
        "print(\"   Comparable:          ~78.8% (70% de puntos)\")\n",
        "print(\"   +1.0% mejor:         >79.8% (85% de puntos)\")\n",
        "print(\"   +1.5% mejor:         >80.3% (100% de puntos)\")\n",
        "\n",
        "print(f\"\\n MEJOR MODELO TASK 3: {best_task3_name} ({best_task3_score:.2f}%)\")\n",
        "\n",
        "if best_task3_score > baseline:\n",
        "    print(f\"    SUPER√ì el baseline (+{best_task3_score - baseline:.2f}%)\")\n",
        "else:\n",
        "    print(f\"     Por debajo del baseline ({best_task3_score - baseline:.2f}%)\")\n",
        "\n",
        "print(f\"\\n Se usar√° {best_task3_key} para la submission de Task 3\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up5ZqvHwZuQ4",
        "outputId": "56d43092-4946-40b7-f6ab-acd696d8bc59"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " RESUMEN TASK 3: ATTENTION MECHANISMS\n",
            "================================================================================\n",
            "\n",
            "Modelo                    F-score      vs Baseline     Status\n",
            "----------------------------------------------------------------------\n",
            "Task 1.3 (Baseline)        78.92%      +0.00%       ‚úÖ 70% pts\n",
            "Task 3.1 (SE)              77.01%      -1.92%       ‚ö†Ô∏è 60% pts\n",
            "Task 3.2 (MHA)             80.53%      +1.60%       üéâ 100% pts\n",
            "\n",
            "----------------------------------------------------------------------\n",
            " REFERENCIAS Task 3 (onsite test):\n",
            "   Baseline (Task 1.3): 78.8%\n",
            "   Comparable:          ~78.8% (70% de puntos)\n",
            "   +1.0% mejor:         >79.8% (85% de puntos)\n",
            "   +1.5% mejor:         >80.3% (100% de puntos)\n",
            "\n",
            " MEJOR MODELO TASK 3: Task 3.2 (MHA) (80.53%)\n",
            "    SUPER√ì el baseline (+1.60%)\n",
            "\n",
            " Se usar√° MHA para la submission de Task 3\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# GENERAR PREDICCI√ìN TASK 3 - MHA\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üì§ GENERANDO PREDICCI√ìN TASK 3 - MULTI-HEAD ATTENTION\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"üéØ Modelo seleccionado: ResNet18 + MHA\")\n",
        "print(f\"   Offsite score: 80.53%\")\n",
        "print(f\"   Supera baseline: +1.60%\")\n",
        "print(f\"   Supera threshold +1.5%: ‚úÖ (potencial 100% de puntos)\\n\")\n",
        "\n",
        "# Generar predicci√≥n onsite\n",
        "pred_mha = generate_predictions(\n",
        "    resnet_mha_trained,\n",
        "    onsite_loader,\n",
        "    DEVICE,\n",
        "    \"task3_mha.csv\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ PREDICCI√ìN TASK 3 GENERADA\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nüìÅ Archivo listo para Kaggle:\")\n",
        "print(\"   ‚úÖ task3_mha.csv\")\n",
        "print(\"\\nüéØ Score esperado en Kaggle:\")\n",
        "print(\"   Offsite: 80.53%\")\n",
        "print(\"   Onsite esperado: ~80-82%\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-S2vGGiacH2",
        "outputId": "3d74c5c2-1311-4e8e-ad5a-727abf1937bb"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üì§ GENERANDO PREDICCI√ìN TASK 3 - MULTI-HEAD ATTENTION\n",
            "================================================================================\n",
            "\n",
            "üéØ Modelo seleccionado: ResNet18 + MHA\n",
            "   Offsite score: 80.53%\n",
            "   Supera baseline: +1.60%\n",
            "   Supera threshold +1.5%: ‚úÖ (potencial 100% de puntos)\n",
            "\n",
            "\n",
            "üîÆ Generando predicciones con task3_mha.csv...\n",
            "‚úÖ Predicciones guardadas en: ./results/task3_mha.csv\n",
            "   Total predicciones: 250\n",
            "\n",
            "üìä Distribuci√≥n de predicciones:\n",
            "   DR (D):  198 positivos\n",
            "   G:       40 positivos\n",
            "   AMD (A): 24 positivos\n",
            "\n",
            "================================================================================\n",
            "‚úÖ PREDICCI√ìN TASK 3 GENERADA\n",
            "================================================================================\n",
            "\n",
            "üìÅ Archivo listo para Kaggle:\n",
            "   ‚úÖ task3_mha.csv\n",
            "\n",
            "üéØ Score esperado en Kaggle:\n",
            "   Offsite: 80.53%\n",
            "   Onsite esperado: ~80-82%\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# DESCARGAR CSV TASK 3\n",
        "# ============================================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\" DESCARGANDO ARCHIVO CSV - TASK 3\\n\")\n",
        "\n",
        "csv_path = './results/task3_mha.csv'\n",
        "print(f\"‚¨á  Descargando: {csv_path}\")\n",
        "files.download(csv_path)\n",
        "\n",
        "print(\"\\n Archivo descargado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Yzn4l23AakZh",
        "outputId": "9b7712dc-ef3d-4510-ae98-f3ed6bda2f46"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DESCARGANDO ARCHIVO CSV - TASK 3\n",
            "\n",
            "‚¨á  Descargando: ./results/task3_mha.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e856b7af-748b-45ef-aa9d-d18fee4bb4c2\", \"task3_mha.csv\", 5042)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Archivo descargado!\n"
          ]
        }
      ]
    }
  ]
}